- hosts: control-plane
  become: yes
  tasks:
    - name: Install required packages
      apt:
        name: conntrack
        state: present
        update_cache: yes

    - name: Create an Empty file for Kubeadm configuring
      copy:
        content: ""
        dest: /etc/kubernetes/kubeadm-config.yaml
        force: no

    - name: Configure container runtime and control plane
      block:
        - blockinfile:
            path: /etc/kubernetes/kubeadm-config.yaml
            block: |
              kind: ClusterConfiguration
              apiVersion: kubeadm.k8s.io/v1beta4
              networking:
                podSubnet: "{{ pod_cidr }}"
              controlPlaneEndpoint: "{{ hostvars['nginx-server']['ansible_host'] }}:6443"
              ---
              kind: KubeletConfiguration
              apiVersion: kubelet.config.k8s.io/v1beta1
              runtimeRequestTimeout: "15m"
              cgroupDriver: "systemd"
              systemReserved:
                cpu: 100m
                memory: 350M
              kubeReserved:
                cpu: 100m
                memory: 50M
              enforceNodeAllocatable:
              - pods
      rescue:
        - name: Fail with custom message
          fail:
            msg: "Failed to configure container runtime and control plane. Playbook will exit!"


    - name: Check if cluster is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: admin_conf_exists

    - name: Initialize the first control plane
      shell: kubeadm init --config /etc/kubernetes/kubeadm-config.yaml --upload-certs >> cluster_initialized.log
      args:
        chdir: $HOME
      when: inventory_hostname == "k8s-control-plane-1" and not admin_conf_exists.stat.exists

    - name: Create .kube directory
      file:
        path: $HOME/.kube
        state: directory
        mode: 0755

    - name: Copy admin.conf to User's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: $HOME/.kube/config
        remote_src: yes
        owner: "{{ ansible_user }}"
      when: inventory_hostname == "k8s-control-plane-1"

- hosts: k8s-control-plane-1
  become: yes
  tasks:
    - name: Get join command for control plane
      shell: kubeadm token create --print-join-command
      register: join_command_control_plane

    - name: Get certificate key
      shell: kubeadm init phase upload-certs --upload-certs | tail -1
      register: cert_key

    - name: Set control plane join facts
      set_fact:
        control_plane_join_command: "{{ join_command_control_plane.stdout }}"
        certificate_key: "{{ cert_key.stdout }}"

- hosts: control-plane
  become: yes
  tasks:
    - name: Stop kubelet service
      service:
        name: kubelet
        state: stopped
      when: inventory_hostname != "k8s-control-plane-1"
      ignore_errors: yes

    - name: Kill processes using kubernetes ports
      shell: |
        pkill -f kube-apiserver || true
        pkill -f kube-controller-manager || true
        pkill -f kube-scheduler || true
        pkill -f etcd || true
        sleep 3
      when: inventory_hostname != "k8s-control-plane-1"
      ignore_errors: yes

    - name: Clean up previous failed join attempts
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/kubernetes/kubelet.conf
        - /etc/kubernetes/pki/ca.crt
        - /var/lib/kubelet
        - /etc/kubernetes/pki
        - /var/lib/etcd
        - /etc/kubernetes/manifests
      when: inventory_hostname != "k8s-control-plane-1"
      ignore_errors: yes

    - name: Join additional control plane nodes
      shell: "{{ hostvars['k8s-control-plane-1']['control_plane_join_command'] }} --control-plane --certificate-key {{ hostvars['k8s-control-plane-1']['certificate_key'] }}"
      when: inventory_hostname != "k8s-control-plane-1"

    - name: Install Pod Network
      shell: kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml >> pod_network_setup.log
      args:
        chdir: $HOME
        creates: pod_network_setup.log
      when: inventory_hostname == "k8s-control-plane-1"

- hosts: k8s-control-plane-1
  become: yes
  tasks:
    - name: Get worker join command
      shell: kubeadm token create --print-join-command
      register: worker_join_command

    - name: Save join command to a variable
      set_fact:
        worker_join_command: "{{ worker_join_command.stdout }}"

- hosts: workers
  become: yes
  tasks:
    - name: Install required packages
      apt:
        name: conntrack
        state: present
        update_cache: yes

    - name: Stop kubelet service
      service:
        name: kubelet
        state: stopped
      ignore_errors: yes

    - name: Kill processes using kubernetes ports
      shell: |
        pkill -f kubelet || true
        sleep 2
      ignore_errors: yes

    - name: Clean up previous failed join attempts
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/kubernetes/kubelet.conf
        - /etc/kubernetes/pki/ca.crt
        - /var/lib/kubelet
        - /etc/kubernetes/pki
      ignore_errors: yes

    - name: Get node status from cluster
      shell: |
        kubectl get node {{ inventory_hostname }} --no-headers 2>/dev/null || echo "NotFound"
      register: node_status
      delegate_to: k8s-control-plane-1
      ignore_errors: yes

    - name: Delete existing node from cluster
      shell: |
        kubectl delete node {{ inventory_hostname }} --ignore-not-found=true
      delegate_to: k8s-control-plane-1
      when: node_status.stdout != "NotFound"

    - name: Join worker nodes
      shell: "{{ hostvars['k8s-control-plane-1']['worker_join_command'] }}"
