apiVersion: v1
data:
  admin.enabled: "true"
  application.instanceLabelKey: argocd.argoproj.io/instance
  application.sync.impersonation.enabled: "false"
  dex.config: |
    connectors:
    - config:
        issuer: "https://auth.jazziro.com/application/o/argocd/"
        redirectURI: "https://argocd.local.jazziro.com/api/dex/callback"
        clientID: argocd
        clientSecret: $dex.authentik.clientSecret
        insecureEnableGroups: true
        scopes:
          - openid
          - profile
          - email
      name: authentik
      type: oidc
      id: authentik
  exec.enabled: "true"
  server.rbac.log.enforce.enable: "false"
  statusbadge.enabled: "false"
  timeout.hard.reconciliation: 0s
  timeout.reconciliation: 180s
  url: https://argocd.local.jazziro.com
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: argocd
    meta.helm.sh/release-namespace: argocd
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: argocd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: argocd-cm
    app.kubernetes.io/part-of: argocd
    app.kubernetes.io/version: v2.14.11
    helm.sh/chart: argo-cd-7.8.28
  name: argocd-cm
---
apiVersion: v1
data:
  policy.csv: |
    g, ArgoCD Admins, role:admin
    g, authentik Admins, role:admin
    g, ArgoCD Viewers, role:readonly
  policy.default: ""
  policy.matchMode: glob
  scopes: '[groups]'
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: argocd
    meta.helm.sh/release-namespace: argocd
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: argocd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: argocd-rbac-cm
    app.kubernetes.io/part-of: argocd
    app.kubernetes.io/version: v2.14.11
    helm.sh/chart: argo-cd-7.8.28
  name: argocd-rbac-cm
---
apiVersion: v1
data:
  ssh_known_hosts: |
    [ssh.github.com]:443 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=
    [ssh.github.com]:443 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl
    [ssh.github.com]:443 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=
    bitbucket.org ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBPIQmuzMBuKdWeF4+a2sjSSpBK0iqitSQ+5BM9KhpexuGt20JpTVM7u5BDZngncgrqDMbWdxMWWOGtZ9UgbqgZE=
    bitbucket.org ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIazEu89wgQZ4bqs3d63QSMzYVa0MuJ2e2gKTKqu+UUO
    bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDQeJzhupRu0u0cdegZIa8e86EG2qOCsIsD1Xw0xSeiPDlCr7kq97NLmMbpKTX6Esc30NuoqEEHCuc7yWtwp8dI76EEEB1VqY9QJq6vk+aySyboD5QF61I/1WeTwu+deCbgKMGbUijeXhtfbxSxm6JwGrXrhBdofTsbKRUsrN1WoNgUa8uqN1Vx6WAJw1JHPhglEGGHea6QICwJOAr/6mrui/oB7pkaWKHj3z7d1IC4KWLtY47elvjbaTlkN04Kc/5LFEirorGYVbt15kAUlqGM65pk6ZBxtaO3+30LVlORZkxOh+LKL/BvbZ/iRNhItLqNyieoQj/uh/7Iv4uyH/cV/0b4WDSd3DptigWq84lJubb9t/DnZlrJazxyDCulTmKdOR7vs9gMTo+uoIrPSb8ScTtvw65+odKAlBj59dhnVp9zd7QUojOpXlL62Aw56U4oO+FALuevvMjiWeavKhJqlR7i5n9srYcrNV7ttmDw7kf/97P5zauIhxcjX+xHv4M=
    github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=
    github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl
    github.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=
    gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=
    gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf
    gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9
    ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H
    vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: argocd
    meta.helm.sh/release-namespace: argocd
  labels:
    app.kubernetes.io/instance: argocd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: argocd-ssh-known-hosts-cm
    app.kubernetes.io/part-of: argocd
    app.kubernetes.io/version: v2.14.11
    helm.sh/chart: argo-cd-7.8.28
  name: argocd-ssh-known-hosts-cm
---
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: argocd
    meta.helm.sh/release-namespace: argocd
  labels:
    app.kubernetes.io/instance: argocd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: argocd-tls-certs-cm
    app.kubernetes.io/part-of: argocd
    app.kubernetes.io/version: v2.14.11
    helm.sh/chart: argo-cd-7.8.28
  name: argocd-tls-certs-cm
---
apiVersion: v1
data:
  admin.password: JDJhJDEwJEVLaHc0dzBoMkZyeS40cUkyME0xRC5PbS9CakI3OUM3WTgyWVdpcEd5WWh1bnBRanUyZS42
  admin.passwordMtime: MjAyNS0wNC0yNlQyMjo1NDoxNVo=
  dex.authentik.clientSecret: K2pVeGMvbUtNM3N1SHVlM2tFSG5yNVh5OUtad2FtSEdCQngyQW1Zb0w4dz0=
  server.secretkey: dURIMm1LVUh5b3FoZGJLR1V2NHJKZmhvN1pzd1FicHdIYlc2TWx5Nll0az0=
kind: Secret
metadata:
  annotations:
    meta.helm.sh/release-name: argocd
    meta.helm.sh/release-namespace: argocd
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: argocd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: argocd-secret
    app.kubernetes.io/part-of: argocd
    app.kubernetes.io/version: v2.14.11
    helm.sh/chart: argo-cd-7.8.28
  name: argocd-secret
type: Opaque
---
apiVersion: argoproj.io/v1alpha1
kind: AppProject
metadata:
  name: default
spec:
  clusterResourceWhitelist:
  - group: '*'
    kind: '*'
  destinations:
  - namespace: '*'
    server: '*'
  sourceRepos:
  - '*'
status: {}
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: authentik
spec:
  destination:
    namespace: zero-trust
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: authentik
    helm:
      releaseName: authentik
      values: |
        authentik:
          secret_key: wCFQTncvyQfoU/meuHMTi5x5vSOEewn79E1G5X25rsSDRcsSv3zSsjjjJDT9Ew0+BQo643UoofSZGnOE
          # This sends anonymous usage-data, stack traces on errors and
          # performance data to authentik.error-reporting.a7k.io, and is fully opt-in
          error_reporting:
            enabled: true
          postgresql:
            password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
        server:
          ingress:
            enabled: false
        postgresql:
          enabled: true
          image:
            tag: 16.6.0-debian-12-r1
          auth:
            password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
          primary:
            persistence:
              enabled: true
              mountPath: /bitnami/postgresql/data
              existingClaim: authentik-db
        redis:
          enabled: true
          master:
            persistence:
              enabled: true
              existingClaim: authentik-redis
    repoURL: https://charts.goauthentik.io/
    targetRevision: 2025.2.4
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T17:26:06Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-07T17:25:14Z"
    deployedAt: "2025-07-07T17:25:16Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 2025.2.4
    source:
      chart: authentik
      helm:
        releaseName: authentik
        values: |
          authentik:
            secret_key: wCFQTncvyQfoU/meuHMTi5x5vSOEewn79E1G5X25rsSDRcsSv3zSsjjjJDT9Ew0+BQo643UoofSZGnOE
            # This sends anonymous usage-data, stack traces on errors and
            # performance data to authentik.error-reporting.a7k.io, and is fully opt-in
            error_reporting:
              enabled: true
            postgresql:
              password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
          server:
            ingress:
              enabled: false
          postgresql:
            enabled: true
            image:
              tag: 16.6.0-debian-12-r1
            auth:
              password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
            primary:
              persistence:
                enabled: true
                mountPath: /bitnami/postgresql/data
                existingClaim: authentik-db
          redis:
            enabled: true
            master:
              persistence:
                enabled: true
                existingClaim: authentik-redis
      repoURL: https://charts.goauthentik.io/
      targetRevision: 2025.2.4
  operationState:
    finishedAt: "2025-07-08T19:43:47Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        autoHealAttemptsCount: 1
        prune: true
        resources:
        - kind: Secret
          name: authentik-postgresql
        revision: 2025.2.4
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-07-08T19:43:44Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/authentik-postgresql configured
        name: authentik-postgresql
        namespace: zero-trust
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 2025.2.4
      source:
        chart: authentik
        helm:
          releaseName: authentik
          values: |
            authentik:
              secret_key: wCFQTncvyQfoU/meuHMTi5x5vSOEewn79E1G5X25rsSDRcsSv3zSsjjjJDT9Ew0+BQo643UoofSZGnOE
              # This sends anonymous usage-data, stack traces on errors and
              # performance data to authentik.error-reporting.a7k.io, and is fully opt-in
              error_reporting:
                enabled: true
              postgresql:
                password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
            server:
              ingress:
                enabled: false
            postgresql:
              enabled: true
              image:
                tag: 16.6.0-debian-12-r1
              auth:
                password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
              primary:
                persistence:
                  enabled: true
                  mountPath: /bitnami/postgresql/data
                  existingClaim: authentik-db
            redis:
              enabled: true
              master:
                persistence:
                  enabled: true
                  existingClaim: authentik-redis
        repoURL: https://charts.goauthentik.io/
        targetRevision: 2025.2.4
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ConfigMap
    name: authentik-postgresql-extended-configuration
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ConfigMap
    name: authentik-redis-configuration
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ConfigMap
    name: authentik-redis-health
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ConfigMap
    name: authentik-redis-scripts
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: Secret
    name: authentik
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: Secret
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: authentik-postgresql-hl
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: authentik-redis-headless
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: authentik-redis-master
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: authentik-server
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: authentik
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: authentik-redis-master
    namespace: zero-trust
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: authentik-server
    namespace: zero-trust
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: authentik-worker
    namespace: zero-trust
    status: Synced
    version: v1
  - group: apps
    health:
      message: 'partitioned roll out complete: 1 new pods have been updated...'
      status: Healthy
    kind: StatefulSet
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - group: apps
    health:
      message: statefulset rolling update complete 1 pods at revision authentik-redis-master-64896974fc...
      status: Healthy
    kind: StatefulSet
    name: authentik-redis-master
    namespace: zero-trust
    status: Synced
    version: v1
  - group: networking.k8s.io
    kind: NetworkPolicy
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - group: networking.k8s.io
    kind: NetworkPolicy
    name: authentik-redis
    namespace: zero-trust
    status: Synced
    version: v1
  - group: policy
    health:
      message: PodDisruptionBudget has SufficientPods
      status: Healthy
    kind: PodDisruptionBudget
    name: authentik-postgresql
    namespace: zero-trust
    status: Synced
    version: v1
  - group: policy
    health:
      message: PodDisruptionBudget has SufficientPods
      status: Healthy
    kind: PodDisruptionBudget
    name: authentik-redis-master
    namespace: zero-trust
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: authentik-zero-trust
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: authentik-zero-trust
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: authentik
    namespace: zero-trust
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: authentik
    namespace: zero-trust
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - docker.io/bitnami/postgresql:16.6.0-debian-12-r1
    - docker.io/bitnami/redis:7.4.1-debian-12-r0
    - ghcr.io/goauthentik/server:2025.2.4
  sync:
    comparedTo:
      destination:
        namespace: zero-trust
        server: https://kubernetes.default.svc
      source:
        chart: authentik
        helm:
          releaseName: authentik
          values: |
            authentik:
              secret_key: wCFQTncvyQfoU/meuHMTi5x5vSOEewn79E1G5X25rsSDRcsSv3zSsjjjJDT9Ew0+BQo643UoofSZGnOE
              # This sends anonymous usage-data, stack traces on errors and
              # performance data to authentik.error-reporting.a7k.io, and is fully opt-in
              error_reporting:
                enabled: true
              postgresql:
                password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
            server:
              ingress:
                enabled: false
            postgresql:
              enabled: true
              image:
                tag: 16.6.0-debian-12-r1
              auth:
                password: 5W8Xc5m/pysWGMvKbkzlvaVkpvHUbz9d6q0DUfwpYpUcDZQ1
              primary:
                persistence:
                  enabled: true
                  mountPath: /bitnami/postgresql/data
                  existingClaim: authentik-db
            redis:
              enabled: true
              master:
                persistence:
                  enabled: true
                  existingClaim: authentik-redis
        repoURL: https://charts.goauthentik.io/
        targetRevision: 2025.2.4
    revision: 2025.2.4
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: beszel-agent
spec:
  destination:
    namespace: beszel
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      commonLabels:
        app.kubernetes.io/instance: beszel-agent-prod
      namespace: beszel
    path: kustomize/beszel-agent/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: develop
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-07T16:58:43Z"
    message: 'Failed to load target state: failed to generate manifest for source
      1 of 1: rpc error: code = Unknown desc = unable to resolve ''develop'' to a
      commit SHA'
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-20T12:47:08Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-14T14:20:16Z"
    deployedAt: "2025-04-14T14:20:16Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 4ffdf0bac9c5b4594d28a269dd14ba86755e352c
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: beszel-agent-prod
        namespace: beszel
      path: kustomize/beszel-agent/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  operationState:
    finishedAt: "2025-04-14T14:20:16Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 4ffdf0bac9c5b4594d28a269dd14ba86755e352c
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-04-14T14:20:16Z"
    syncResult:
      resources:
      - group: apps
        hookPhase: Running
        kind: DaemonSet
        message: daemonset.apps/beszel-agent serverside-applied
        name: beszel-agent
        namespace: beszel
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 4ffdf0bac9c5b4594d28a269dd14ba86755e352c
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: beszel-agent-prod
          namespace: beszel
        path: kustomize/beszel-agent/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: development
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - group: apps
    health:
      status: Healthy
    kind: DaemonSet
    name: beszel-agent
    namespace: beszel
    requiresPruning: true
    status: Unknown
    version: v1
  sourceHydrator: {}
  summary:
    images:
    - henrygd/beszel-agent:0.10.2
  sync:
    comparedTo:
      destination:
        namespace: beszel
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: beszel-agent-prod
          namespace: beszel
        path: kustomize/beszel-agent/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: cert-manager
spec:
  destination:
    namespace: cert-manager
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: cert-manager
    helm:
      releaseName: cert-manager
      values: |
        installCRDs: true
    repoURL: https://charts.jetstack.io
    targetRevision: v1.17.0
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T16:59:40Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-05T16:34:14Z"
    deployedAt: "2025-04-05T16:35:37Z"
    id: 0
    initiatedBy:
      automated: true
    revision: v1.17.0
    source:
      chart: cert-manager
      helm:
        releaseName: cert-manager
        values: |
          installCRDs: true
      repoURL: https://charts.jetstack.io
      targetRevision: v1.17.0
  operationState:
    finishedAt: "2025-04-05T16:35:37Z"
    message: successfully synced (no more tasks)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: v1.17.0
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-04-05T16:34:14Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/cert-manager created
        name: cert-manager
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/cert-manager-webhook created
        name: cert-manager-webhook
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/cert-manager-cainjector created
        name: cert-manager-cainjector
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/cert-manager created
        name: cert-manager
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io
          created
        name: certificaterequests.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io
          created
        name: orders.acme.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io
          created
        name: challenges.acme.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io
          created
        name: certificates.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io
          created
        name: clusterissuers.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io
          created
        name: issuers.cert-manager.io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[update
          patch] APIGroups:[cert-manager.io] Resources:[clusterissuers clusterissuers/status]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[cert-manager.io]
          Resources:[clusterissuers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create update delete] APIGroups:[] Resources:[secrets] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[create patch] APIGroups:[] Resources:[events]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers
          configured. Warning: resource clusterroles/cert-manager-controller-clusterissuers
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-clusterissuers
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[update
          patch] APIGroups:[acme.cert-manager.io] Resources:[challenges challenges/status]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[acme.cert-manager.io]
          Resources:[challenges] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[issuers clusterissuers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[]
          Resources:[secrets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          patch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create delete] APIGroups:[] Resources:[pods services] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create delete update] APIGroups:[networking.k8s.io]
          Resources:[ingresses] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create delete update] APIGroups:[gateway.networking.k8s.io] Resources:[httproutes]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create] APIGroups:[route.openshift.io]
          Resources:[routes/custom-host] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[acme.cert-manager.io] Resources:[challenges/finalizers] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[] Resources:[secrets]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges
          configured. Warning: resource clusterroles/cert-manager-controller-challenges
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-challenges
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[update
          patch] APIGroups:[cert-manager.io] Resources:[certificates certificates/status
          certificaterequests certificaterequests/status] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[certificates certificaterequests
          clusterissuers issuers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[cert-manager.io] Resources:[certificates/finalizers certificaterequests/finalizers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create delete get list
          watch] APIGroups:[acme.cert-manager.io] Resources:[orders] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create update delete patch]
          APIGroups:[] Resources:[secrets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          patch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}.
          clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates
          configured. Warning: resource clusterroles/cert-manager-controller-certificates
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-certificates
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[approve]
          APIGroups:[cert-manager.io] Resources:[signers] ResourceNames:[issuers.cert-manager.io/*
          clusterissuers.cert-manager.io/*] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io
          configured. Warning: resource clusterroles/cert-manager-controller-approve:cert-manager-io
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-approve:cert-manager-io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[update
          patch] APIGroups:[cert-manager.io] Resources:[issuers issuers/status] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[cert-manager.io]
          Resources:[issuers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create update delete] APIGroups:[] Resources:[secrets] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[create patch] APIGroups:[] Resources:[events]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers
          configured. Warning: resource clusterroles/cert-manager-controller-issuers
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-issuers
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-edit reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create
          delete deletecollection patch update] APIGroups:[cert-manager.io] Resources:[certificates
          certificaterequests issuers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[cert-manager.io] Resources:[certificates/status] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[create delete deletecollection patch update]
          APIGroups:[acme.cert-manager.io] Resources:[challenges orders] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-edit
          configured. Warning: resource clusterroles/cert-manager-edit is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager-edit
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch update] APIGroups:[certificates.k8s.io] Resources:[certificatesigningrequests]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update patch] APIGroups:[certificates.k8s.io]
          Resources:[certificatesigningrequests/status] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[sign]
          APIGroups:[certificates.k8s.io] Resources:[signers] ResourceNames:[issuers.cert-manager.io/*
          clusterissuers.cert-manager.io/*] NonResourceURLs:[]}\n\t\t{Verbs:[create]
          APIGroups:[authorization.k8s.io] Resources:[subjectaccessreviews] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests
          configured. Warning: resource clusterroles/cert-manager-controller-certificatesigningrequests
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-certificatesigningrequests
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[certificates] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[] Resources:[secrets]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get create update patch]
          APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch update patch] APIGroups:[admissionregistration.k8s.io] Resources:[validatingwebhookconfigurations
          mutatingwebhookconfigurations] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch update patch] APIGroups:[apiregistration.k8s.io] Resources:[apiservices]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch update
          patch] APIGroups:[apiextensions.k8s.io] Resources:[customresourcedefinitions]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector
          configured. Warning: resource clusterroles/cert-manager-cainjector is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager-cainjector
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-cluster-view
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[clusterissuers] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-cluster-view
          configured. Warning: resource clusterroles/cert-manager-cluster-view is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-cluster-view
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create
          update delete] APIGroups:[cert-manager.io] Resources:[certificates certificaterequests]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[cert-manager.io]
          Resources:[certificates certificaterequests issuers clusterissuers] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[networking.k8s.io]
          Resources:[ingresses] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[networking.k8s.io] Resources:[ingresses/finalizers] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[gateway.networking.k8s.io]
          Resources:[gateways httproutes] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[gateway.networking.k8s.io] Resources:[gateways/finalizers httproutes/finalizers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create patch] APIGroups:[]
          Resources:[events] ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim
          configured. Warning: resource clusterroles/cert-manager-controller-ingress-shim
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-ingress-shim
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create]
          APIGroups:[authorization.k8s.io] Resources:[subjectaccessreviews] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews
          configured. Warning: resource clusterroles/cert-manager-webhook:subjectaccessreviews
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-webhook:subjectaccessreviews
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-view reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[certificates certificaterequests
          issuers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch]
          APIGroups:[acme.cert-manager.io] Resources:[challenges orders] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-view
          configured. Warning: resource clusterroles/cert-manager-view is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager-view
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[update
          patch] APIGroups:[acme.cert-manager.io] Resources:[orders orders/status]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[acme.cert-manager.io]
          Resources:[orders challenges] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[cert-manager.io] Resources:[clusterissuers issuers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create delete] APIGroups:[acme.cert-manager.io]
          Resources:[challenges] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[acme.cert-manager.io] Resources:[orders/finalizers] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[] Resources:[secrets]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create patch] APIGroups:[]
          Resources:[events] ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders
          configured. Warning: resource clusterroles/cert-manager-controller-orders
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-orders
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager-cainjector Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector
          configured. Warning: resource clusterrolebindings/cert-manager-cainjector
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-cainjector
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates
          configured. Warning: resource clusterrolebindings/cert-manager-controller-certificates
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-certificates
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders
          configured. Warning: resource clusterrolebindings/cert-manager-controller-orders
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-orders
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers
          configured. Warning: resource clusterrolebindings/cert-manager-controller-clusterissuers
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-clusterissuers
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io
          configured. Warning: resource clusterrolebindings/cert-manager-controller-approve:cert-manager-io
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-approve:cert-manager-io
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim
          configured. Warning: resource clusterrolebindings/cert-manager-controller-ingress-shim
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-ingress-shim
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers
          configured. Warning: resource clusterrolebindings/cert-manager-controller-issuers
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-issuers
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges
          configured. Warning: resource clusterrolebindings/cert-manager-controller-challenges
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-challenges
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests
          configured. Warning: resource clusterrolebindings/cert-manager-controller-certificatesigningrequests
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-controller-certificatesigningrequests
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager-webhook Namespace:cert-manager}. clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews
          configured. Warning: resource clusterrolebindings/cert-manager-webhook:subjectaccessreviews
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-webhook:subjectaccessreviews
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: Role
        message: "role.rbac.authorization.k8s.io/cert-manager-tokenrequest reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create]
          APIGroups:[] Resources:[serviceaccounts/token] ResourceNames:[cert-manager]
          NonResourceURLs:[]}. role.rbac.authorization.k8s.io/cert-manager-tokenrequest
          configured. Warning: resource roles/cert-manager-tokenrequest is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager-tokenrequest
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: Role
        message: "role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          update patch] APIGroups:[coordination.k8s.io] Resources:[leases] ResourceNames:[cert-manager-cainjector-leader-election
          cert-manager-cainjector-leader-election-core] NonResourceURLs:[]}\n\t\t{Verbs:[create]
          APIGroups:[coordination.k8s.io] Resources:[leases] ResourceNames:[] NonResourceURLs:[]}.
          role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection configured.
          Warning: resource roles/cert-manager-cainjector:leaderelection is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager-cainjector:leaderelection
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: Role
        message: "role.rbac.authorization.k8s.io/cert-manager:leaderelection reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          update patch] APIGroups:[coordination.k8s.io] Resources:[leases] ResourceNames:[cert-manager-controller]
          NonResourceURLs:[]}\n\t\t{Verbs:[create] APIGroups:[coordination.k8s.io]
          Resources:[leases] ResourceNames:[] NonResourceURLs:[]}. role.rbac.authorization.k8s.io/cert-manager:leaderelection
          configured. Warning: resource roles/cert-manager:leaderelection is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: cert-manager:leaderelection
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: Role
        message: "role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch update] APIGroups:[] Resources:[secrets] ResourceNames:[cert-manager-webhook-ca]
          NonResourceURLs:[]}\n\t\t{Verbs:[create] APIGroups:[] Resources:[secrets]
          ResourceNames:[] NonResourceURLs:[]}. role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving
          configured. Warning: resource roles/cert-manager-webhook:dynamic-serving
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-webhook:dynamic-serving
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: RoleBinding
        message: "rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager-cainjector Namespace:cert-manager}. rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection
          configured. Warning: resource rolebindings/cert-manager-cainjector:leaderelection
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-cainjector:leaderelection
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: RoleBinding
        message: "rolebinding.rbac.authorization.k8s.io/cert-manager-cert-manager-tokenrequest
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. rolebinding.rbac.authorization.k8s.io/cert-manager-cert-manager-tokenrequest
          configured. Warning: resource rolebindings/cert-manager-cert-manager-tokenrequest
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-cert-manager-tokenrequest
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: RoleBinding
        message: "rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager Namespace:cert-manager}. rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection
          configured. Warning: resource rolebindings/cert-manager:leaderelection is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager:leaderelection
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: RoleBinding
        message: "rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:cert-manager-webhook Namespace:cert-manager}. rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving
          configured. Warning: resource rolebindings/cert-manager-webhook:dynamic-serving
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: cert-manager-webhook:dynamic-serving
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/cert-manager created
        name: cert-manager
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/cert-manager-webhook created
        name: cert-manager-webhook
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/cert-manager-cainjector created
        name: cert-manager-cainjector
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/cert-manager-cainjector created
        name: cert-manager-cainjector
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/cert-manager created
        name: cert-manager
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/cert-manager-webhook created
        name: cert-manager-webhook
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: admissionregistration.k8s.io
        hookPhase: Succeeded
        kind: MutatingWebhookConfiguration
        message: mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook
          created
        name: cert-manager-webhook
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: admissionregistration.k8s.io
        hookPhase: Succeeded
        kind: ValidatingWebhookConfiguration
        message: validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook
          created
        name: cert-manager-webhook
        namespace: cert-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        hookType: PostSync
        kind: ServiceAccount
        message: cert-manager-startupapicheck created
        name: cert-manager-startupapicheck
        namespace: cert-manager
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: Role
        message: cert-manager-startupapicheck:create-cert created
        name: cert-manager-startupapicheck:create-cert
        namespace: cert-manager
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: RoleBinding
        message: cert-manager-startupapicheck:create-cert created
        name: cert-manager-startupapicheck:create-cert
        namespace: cert-manager
        syncPhase: PostSync
        version: v1
      - group: batch
        hookPhase: Succeeded
        hookType: PostSync
        kind: Job
        message: job.batch/cert-manager-startupapicheck created
        name: cert-manager-startupapicheck
        namespace: cert-manager
        syncPhase: PostSync
        version: v1
      revision: v1.17.0
      source:
        chart: cert-manager
        helm:
          releaseName: cert-manager
          values: |
            installCRDs: true
        repoURL: https://charts.jetstack.io
        targetRevision: v1.17.0
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: cert-manager
    namespace: cert-manager
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: cert-manager-cainjector
    namespace: cert-manager
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: cert-manager-webhook
    namespace: cert-manager
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: cert-manager
    namespace: cert-manager
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: cert-manager-cainjector
    namespace: cert-manager
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: cert-manager-webhook
    namespace: cert-manager
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: MutatingWebhookConfiguration
    name: cert-manager-webhook
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: ValidatingWebhookConfiguration
    name: cert-manager-webhook
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: certificaterequests.cert-manager.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: certificates.cert-manager.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: challenges.acme.cert-manager.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: clusterissuers.cert-manager.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: issuers.cert-manager.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: orders.acme.cert-manager.io
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: cert-manager
    namespace: cert-manager
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: cert-manager-cainjector
    namespace: cert-manager
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: cert-manager-webhook
    namespace: cert-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-cainjector
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-cluster-view
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-approve:cert-manager-io
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-certificates
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-certificatesigningrequests
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-challenges
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-clusterissuers
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-ingress-shim
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-issuers
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-controller-orders
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-edit
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-view
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cert-manager-webhook:subjectaccessreviews
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-cainjector
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-approve:cert-manager-io
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-certificates
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-certificatesigningrequests
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-challenges
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-clusterissuers
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-ingress-shim
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-issuers
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-controller-orders
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cert-manager-webhook:subjectaccessreviews
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: cert-manager-tokenrequest
    namespace: cert-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: cert-manager-webhook:dynamic-serving
    namespace: cert-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: cert-manager-cainjector:leaderelection
    namespace: kube-system
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: cert-manager:leaderelection
    namespace: kube-system
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: cert-manager-cert-manager-tokenrequest
    namespace: cert-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: cert-manager-webhook:dynamic-serving
    namespace: cert-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: cert-manager-cainjector:leaderelection
    namespace: kube-system
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: cert-manager:leaderelection
    namespace: kube-system
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - quay.io/jetstack/cert-manager-cainjector:v1.17.0
    - quay.io/jetstack/cert-manager-controller:v1.17.0
    - quay.io/jetstack/cert-manager-webhook:v1.17.0
  sync:
    comparedTo:
      destination:
        namespace: cert-manager
        server: https://kubernetes.default.svc
      source:
        chart: cert-manager
        helm:
          releaseName: cert-manager
          values: |
            installCRDs: true
        repoURL: https://charts.jetstack.io
        targetRevision: v1.17.0
    revision: v1.17.0
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: cloudflare-ddns
spec:
  destination:
    namespace: ddns
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      commonLabels:
        app.kubernetes.io/instance: cloudflare-ddns
    path: kustomize/ddns/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: develop
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-07T16:58:43Z"
    message: 'Failed to load target state: failed to generate manifest for source
      1 of 1: rpc error: code = Unknown desc = unable to resolve ''develop'' to a
      commit SHA'
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-25T21:32:05Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-11T17:00:48Z"
    deployedAt: "2025-04-11T17:00:48Z"
    id: 0
    initiatedBy:
      automated: true
    revision: a746c48b94065398ddfbeb213894f2cbe556fe66
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: cloudflare-ddns
      path: kustomize/ddns/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-12T17:21:49Z"
    deployedAt: "2025-04-12T17:21:49Z"
    id: 1
    initiatedBy:
      automated: true
    revision: c406f0c4490486039d6a959dc995e86aec2049eb
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: cloudflare-ddns
      path: kustomize/ddns/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  operationState:
    finishedAt: "2025-04-12T17:21:49Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: c406f0c4490486039d6a959dc995e86aec2049eb
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-04-12T17:21:49Z"
    syncResult:
      resources:
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/cloudflare-ddns serverside-applied
        name: cloudflare-ddns
        namespace: ddns
        status: Synced
        syncPhase: Sync
        version: v1
      revision: c406f0c4490486039d6a959dc995e86aec2049eb
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: cloudflare-ddns
        path: kustomize/ddns/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: development
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: cloudflare-ddns
    namespace: ddns
    requiresPruning: true
    status: Unknown
    version: v1
  sourceHydrator: {}
  summary:
    images:
    - favonia/cloudflare-ddns:1.15.1
  sync:
    comparedTo:
      destination:
        namespace: ddns
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: cloudflare-ddns
        path: kustomize/ddns/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: cloudnative-postgresql
spec:
  destination:
    namespace: cnpg-system
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: cloudnative-pg
    helm:
      releaseName: cnpg
      values: |
        #
    repoURL: https://cloudnative-pg.github.io/charts
    targetRevision: 0.23.2
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-25T21:31:55Z"
    status: Healthy
  operationState:
    finishedAt: "2025-05-02T20:47:44Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        prune: true
        resources:
        - group: apiextensions.k8s.io
          kind: CustomResourceDefinition
          name: poolers.postgresql.cnpg.io
        revision: 0.23.2
        syncOptions:
        - CreateNamespace=true
        - Replace=true
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2025-05-02T20:47:43Z"
    syncResult:
      resources:
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/poolers.postgresql.cnpg.io
          created
        name: poolers.postgresql.cnpg.io
        namespace: cnpg-system
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 0.23.2
      source:
        chart: cloudnative-pg
        helm:
          releaseName: cnpg
          values: |
            #
        repoURL: https://cloudnative-pg.github.io/charts
        targetRevision: 0.23.2
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ConfigMap
    name: cnpg-controller-manager-config
    namespace: cnpg-system
    status: Synced
    version: v1
  - kind: ConfigMap
    name: cnpg-default-monitoring
    namespace: cnpg-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: cnpg-webhook-service
    namespace: cnpg-system
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: cnpg-cloudnative-pg
    namespace: cnpg-system
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: MutatingWebhookConfiguration
    name: cnpg-mutating-webhook-configuration
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: ValidatingWebhookConfiguration
    name: cnpg-validating-webhook-configuration
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: backups.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: clusterimagecatalogs.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: clusters.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: databases.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: imagecatalogs.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: poolers.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: publications.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: scheduledbackups.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: subscriptions.postgresql.cnpg.io
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: cnpg-cloudnative-pg
    namespace: cnpg-system
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cnpg-cloudnative-pg
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cnpg-cloudnative-pg-edit
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: cnpg-cloudnative-pg-view
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: cnpg-cloudnative-pg
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - ghcr.io/cloudnative-pg/cloudnative-pg:1.25.1
  sync:
    comparedTo:
      destination:
        namespace: cnpg-system
        server: https://kubernetes.default.svc
      source:
        chart: cloudnative-pg
        helm:
          releaseName: cnpg
          values: |
            #
        repoURL: https://cloudnative-pg.github.io/charts
        targetRevision: 0.23.2
    revision: 0.23.2
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: crossplane
spec:
  destination:
    namespace: crossplane-system
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: crossplane
    helm:
      releaseName: crossplane
    repoURL: https://charts.crossplane.io/stable
    targetRevision: 1.20.0
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-08T19:43:16Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-08T19:42:53Z"
    deployedAt: "2025-07-08T19:42:56Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 1.20.0
    source:
      chart: crossplane
      helm:
        releaseName: crossplane
      repoURL: https://charts.crossplane.io/stable
      targetRevision: 1.20.0
  operationState:
    finishedAt: "2025-07-08T19:42:56Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 1.20.0
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-07-08T19:42:53Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/crossplane-system created
        name: crossplane-system
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/rbac-manager created
        name: rbac-manager
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/crossplane created
        name: crossplane
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/crossplane-root-ca created
        name: crossplane-root-ca
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/crossplane-tls-server created
        name: crossplane-tls-server
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/crossplane-tls-client created
        name: crossplane-tls-client
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-admin
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[] Resources:[secrets namespaces] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[rbac.authorization.k8s.io] Resources:[clusterroles
          roles] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*] APIGroups:[rbac.authorization.k8s.io]
          Resources:[clusterrolebindings rolebindings] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[apiextensions.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[pkg.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[secrets.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apiextensions.k8s.io] Resources:[customresourcedefinitions]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-admin
          configured. Warning: resource clusterroles/crossplane:aggregate-to-admin
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: crossplane:aggregate-to-admin
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-browse
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apiextensions.crossplane.io] Resources:[*] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-browse
          configured. Warning: resource clusterroles/crossplane:aggregate-to-browse
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: crossplane:aggregate-to-browse
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-view
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[namespaces] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apiextensions.crossplane.io] Resources:[*] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[pkg.crossplane.io]
          Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list
          watch] APIGroups:[secrets.crossplane.io] Resources:[*] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-view
          configured. Warning: resource clusterroles/crossplane:aggregate-to-view
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: crossplane:aggregate-to-view
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane-rbac-manager reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create
          update patch delete] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[namespaces] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apps] Resources:[deployments] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update]
          APIGroups:[] Resources:[namespaces/finalizers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apiextensions.crossplane.io] Resources:[compositeresourcedefinitions]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update] APIGroups:[apiextensions.crossplane.io]
          Resources:[compositeresourcedefinitions/finalizers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[pkg.crossplane.io] Resources:[providerrevisions]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update] APIGroups:[pkg.crossplane.io]
          Resources:[providerrevisions/finalizers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[apiextensions.k8s.io] Resources:[customresourcedefinitions]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create
          update patch escalate] APIGroups:[rbac.authorization.k8s.io] Resources:[clusterroles
          roles] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[bind] APIGroups:[rbac.authorization.k8s.io]
          Resources:[clusterroles] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[rbac.authorization.k8s.io] Resources:[clusterrolebindings] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list create update patch watch delete]
          APIGroups:[ coordination.k8s.io] Resources:[configmaps leases] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/crossplane-rbac-manager
          configured. Warning: resource clusterroles/crossplane-rbac-manager is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: crossplane-rbac-manager
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-edit
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[] Resources:[secrets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[namespaces] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[apiextensions.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[pkg.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[secrets.crossplane.io] Resources:[*] ResourceNames:[] NonResourceURLs:[]}.
          clusterrole.rbac.authorization.k8s.io/crossplane:aggregate-to-edit configured.
          Warning: resource clusterroles/crossplane:aggregate-to-edit is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: crossplane:aggregate-to-edit
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane-edit reconciled.
          reconciliation required create. clusterrole.rbac.authorization.k8s.io/crossplane-edit
          configured. Warning: resource clusterroles/crossplane-edit is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically.'
        name: crossplane-edit
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane-view reconciled.
          reconciliation required create. clusterrole.rbac.authorization.k8s.io/crossplane-view
          configured. Warning: resource clusterroles/crossplane-view is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically.'
        name: crossplane-view
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane-admin reconciled.
          reconciliation required create. clusterrole.rbac.authorization.k8s.io/crossplane-admin
          configured. Warning: resource clusterroles/crossplane-admin is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically.'
        name: crossplane-admin
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane-browse reconciled.
          reconciliation required create. clusterrole.rbac.authorization.k8s.io/crossplane-browse
          configured. Warning: resource clusterroles/crossplane-browse is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically.'
        name: crossplane-browse
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane:allowed-provider-permissions
          reconciled. reconciliation required create. clusterrole.rbac.authorization.k8s.io/crossplane:allowed-provider-permissions
          configured. Warning: resource clusterroles/crossplane:allowed-provider-permissions
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically.'
        name: crossplane:allowed-provider-permissions
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: 'clusterrole.rbac.authorization.k8s.io/crossplane reconciled. reconciliation
          required create. clusterrole.rbac.authorization.k8s.io/crossplane configured.
          Warning: resource clusterroles/crossplane is missing the kubectl.kubernetes.io/last-applied-configuration
          annotation which is required by  apply.  apply should only be used on resources
          created declaratively by either  create --save-config or  apply. The missing
          annotation will be patched automatically.'
        name: crossplane
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/crossplane:system:aggregate-to-crossplane
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[create
          update patch delete] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[apiextensions.k8s.io] Resources:[customresourcedefinitions customresourcedefinitions/status]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create
          update patch delete] APIGroups:[] Resources:[secrets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[] Resources:[serviceaccounts services] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*]
          APIGroups:[apiextensions.crossplane.io pkg.crossplane.io secrets.crossplane.io]
          Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list
          create update patch delete watch] APIGroups:[extensions apps] Resources:[deployments]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list create update
          patch watch delete] APIGroups:[ coordination.k8s.io] Resources:[configmaps
          leases] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list create
          update patch watch delete] APIGroups:[admissionregistration.k8s.io] Resources:[validatingwebhookconfigurations
          mutatingwebhookconfigurations] ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/crossplane:system:aggregate-to-crossplane
          configured. Warning: resource clusterroles/crossplane:system:aggregate-to-crossplane
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: crossplane:system:aggregate-to-crossplane
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/crossplane reconciled.
          reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:crossplane Namespace:crossplane-system}. clusterrolebinding.rbac.authorization.k8s.io/crossplane
          configured. Warning: resource clusterrolebindings/crossplane is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: crossplane
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/crossplane-rbac-manager
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:rbac-manager Namespace:crossplane-system}. clusterrolebinding.rbac.authorization.k8s.io/crossplane-rbac-manager
          configured. Warning: resource clusterrolebindings/crossplane-rbac-manager
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: crossplane-rbac-manager
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/crossplane-admin reconciled.
          reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:Group
          APIGroup:rbac.authorization.k8s.io Name:crossplane:masters Namespace:}.
          clusterrolebinding.rbac.authorization.k8s.io/crossplane-admin configured.
          Warning: resource clusterrolebindings/crossplane-admin is missing the kubectl.kubernetes.io/last-applied-configuration
          annotation which is required by  apply.  apply should only be used on resources
          created declaratively by either  create --save-config or  apply. The missing
          annotation will be patched automatically."
        name: crossplane-admin
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/crossplane-webhooks created
        name: crossplane-webhooks
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/crossplane created
        name: crossplane
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/crossplane-rbac-manager created
        name: crossplane-rbac-manager
        namespace: crossplane-system
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 1.20.0
      source:
        chart: crossplane
        helm:
          releaseName: crossplane
        repoURL: https://charts.crossplane.io/stable
        targetRevision: 1.20.0
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: Secret
    name: crossplane-root-ca
    namespace: crossplane-system
    status: Synced
    version: v1
  - kind: Secret
    name: crossplane-tls-client
    namespace: crossplane-system
    status: Synced
    version: v1
  - kind: Secret
    name: crossplane-tls-server
    namespace: crossplane-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: crossplane-webhooks
    namespace: crossplane-system
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: crossplane
    namespace: crossplane-system
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: rbac-manager
    namespace: crossplane-system
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: crossplane
    namespace: crossplane-system
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: crossplane-rbac-manager
    namespace: crossplane-system
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane-admin
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane-browse
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane-edit
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane-rbac-manager
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane-view
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:aggregate-to-admin
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:aggregate-to-browse
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:aggregate-to-edit
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:aggregate-to-view
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:allowed-provider-permissions
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: crossplane:system:aggregate-to-crossplane
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: crossplane
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: crossplane-admin
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: crossplane-rbac-manager
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - xpkg.crossplane.io/crossplane/crossplane:v1.20.0
  sync:
    comparedTo:
      destination:
        namespace: crossplane-system
        server: https://kubernetes.default.svc
      source:
        chart: crossplane
        helm:
          releaseName: crossplane
        repoURL: https://charts.crossplane.io/stable
        targetRevision: 1.20.0
    revision: 1.20.0
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: csi-driver-nfs
spec:
  destination:
    namespace: csi-driver-nfs
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: csi-driver-nfs
    helm:
      releaseName: csi-driver-nfs
      values: "storageClass:\n  create: true\n  name: nfs-csi\n  parameters:\n    server:
        192.168.0.15\n    share: /mnt/pool1/k8s/nfs\n    mountPermissions: \"0777\"
        \n  reclaimPolicy: Delete\n  volumeBindingMode: Immediate\n  mountOptions:\n
        \   - nfsvers=4.1\n    - noatime\n    - async  # Better for torrent writes\n"
    repoURL: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
    targetRevision: 4.11.0
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-25T21:42:20Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-05T16:34:36Z"
    deployedAt: "2025-04-05T16:34:39Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 4.11.0
    source:
      chart: csi-driver-nfs
      helm:
        releaseName: csi-driver-nfs
        values: "storageClass:\n  create: true\n  name: nfs-csi\n  parameters:\n    server:
          192.168.0.15\n    share: /mnt/pool1/k8s/nfs\n    mountPermissions: \"0777\"
          \n  reclaimPolicy: Delete\n  volumeBindingMode: Immediate\n  mountOptions:\n
          \   - nfsvers=4.1\n    - noatime\n    - async  # Better for torrent writes\n"
      repoURL: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
      targetRevision: 4.11.0
  operationState:
    finishedAt: "2025-04-05T16:34:39Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 4.11.0
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-04-05T16:34:36Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/csi-driver-nfs created
        name: csi-driver-nfs
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/csi-nfs-node-sa created
        name: csi-nfs-node-sa
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/csi-nfs-controller-sa created
        name: csi-nfs-controller-sa
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: storage.k8s.io
        hookPhase: Running
        kind: StorageClass
        message: storageclass.storage.k8s.io/nfs-csi created
        name: nfs-csi
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/nfs-external-provisioner-role
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch create patch delete] APIGroups:[] Resources:[persistentvolumes]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch update]
          APIGroups:[] Resources:[persistentvolumeclaims] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[storage.k8s.io] Resources:[storageclasses] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[snapshot.storage.k8s.io]
          Resources:[volumesnapshotclasses volumesnapshots] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch update patch] APIGroups:[snapshot.storage.k8s.io] Resources:[volumesnapshotcontents]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get update patch] APIGroups:[snapshot.storage.k8s.io]
          Resources:[volumesnapshotcontents/status] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create update patch] APIGroups:[] Resources:[events] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[storage.k8s.io]
          Resources:[csinodes] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[nodes] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create update patch] APIGroups:[coordination.k8s.io] Resources:[leases]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get] APIGroups:[] Resources:[secrets]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/nfs-external-provisioner-role
          configured. Warning: resource clusterroles/nfs-external-provisioner-role
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: nfs-external-provisioner-role
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/nfs-external-resizer-role
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch update patch] APIGroups:[] Resources:[persistentvolumes] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[] Resources:[persistentvolumeclaims]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update patch] APIGroups:[]
          Resources:[persistentvolumeclaims/status] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[list
          watch create update patch] APIGroups:[] Resources:[events] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create update patch] APIGroups:[coordination.k8s.io]
          Resources:[leases] ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/nfs-external-resizer-role
          configured. Warning: resource clusterroles/nfs-external-resizer-role is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: nfs-external-resizer-role
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/nfs-csi-provisioner-binding
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:csi-nfs-controller-sa Namespace:csi-driver-nfs}. clusterrolebinding.rbac.authorization.k8s.io/nfs-csi-provisioner-binding
          configured. Warning: resource clusterrolebindings/nfs-csi-provisioner-binding
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: nfs-csi-provisioner-binding
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/nfs-csi-resizer-role
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:csi-nfs-controller-sa Namespace:csi-driver-nfs}. clusterrolebinding.rbac.authorization.k8s.io/nfs-csi-resizer-role
          configured. Warning: resource clusterrolebindings/nfs-csi-resizer-role is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: nfs-csi-resizer-role
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: DaemonSet
        message: daemonset.apps/csi-nfs-node created
        name: csi-nfs-node
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/csi-nfs-controller created
        name: csi-nfs-controller
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      - group: storage.k8s.io
        hookPhase: Running
        kind: CSIDriver
        message: csidriver.storage.k8s.io/nfs.csi.k8s.io created
        name: nfs.csi.k8s.io
        namespace: csi-driver-nfs
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 4.11.0
      source:
        chart: csi-driver-nfs
        helm:
          releaseName: csi-driver-nfs
          values: "storageClass:\n  create: true\n  name: nfs-csi\n  parameters:\n
            \   server: 192.168.0.15\n    share: /mnt/pool1/k8s/nfs\n    mountPermissions:
            \"0777\" \n  reclaimPolicy: Delete\n  volumeBindingMode: Immediate\n  mountOptions:\n
            \   - nfsvers=4.1\n    - noatime\n    - async  # Better for torrent writes\n"
        repoURL: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
        targetRevision: 4.11.0
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ServiceAccount
    name: csi-nfs-controller-sa
    namespace: csi-driver-nfs
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: csi-nfs-node-sa
    namespace: csi-driver-nfs
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: DaemonSet
    name: csi-nfs-node
    namespace: csi-driver-nfs
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: csi-nfs-controller
    namespace: csi-driver-nfs
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: nfs-external-provisioner-role
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: nfs-external-resizer-role
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: nfs-csi-provisioner-binding
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: nfs-csi-resizer-role
    status: Synced
    version: v1
  - group: storage.k8s.io
    kind: CSIDriver
    name: nfs.csi.k8s.io
    status: Synced
    version: v1
  - group: storage.k8s.io
    kind: StorageClass
    name: nfs-csi
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.13.0
    - registry.k8s.io/sig-storage/csi-provisioner:v5.2.0
    - registry.k8s.io/sig-storage/csi-resizer:v1.13.1
    - registry.k8s.io/sig-storage/csi-snapshotter:v8.2.0
    - registry.k8s.io/sig-storage/livenessprobe:v2.15.0
    - registry.k8s.io/sig-storage/nfsplugin:v4.11.0
  sync:
    comparedTo:
      destination:
        namespace: csi-driver-nfs
        server: https://kubernetes.default.svc
      source:
        chart: csi-driver-nfs
        helm:
          releaseName: csi-driver-nfs
          values: "storageClass:\n  create: true\n  name: nfs-csi\n  parameters:\n
            \   server: 192.168.0.15\n    share: /mnt/pool1/k8s/nfs\n    mountPermissions:
            \"0777\" \n  reclaimPolicy: Delete\n  volumeBindingMode: Immediate\n  mountOptions:\n
            \   - nfsvers=4.1\n    - noatime\n    - async  # Better for torrent writes\n"
        repoURL: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
        targetRevision: 4.11.0
    revision: 4.11.0
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: gitea
spec:
  destination:
    namespace: gitea
    server: https://kubernetes.default.svc
  project: default
  sources:
  - chart: gitea
    helm:
      releaseName: gitea
      values: |
        global:
          storageClass: "nfs-csi"
        postgresql:
          enabled: false
        postgresql-ha:
          enabled: false
        gitea:
          config:
            attachment:
              STORAGE_TYPE: minio
            lfs:
              STORAGE_TYPE: minio
            picture:
              AVATAR_STORAGE_TYPE: minio
            "storage.packages":
              STORAGE_TYPE: minio
            repo-avatars:
              STORAGE_TYPE: minio
            "storage":
              STORAGE_TYPE: minio
              MINIO_ENDPOINT: s3.local.jazziro.com
              MINIO_LOCATION: joburg-north-1
              MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
              MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
              MINIO_BUCKET: gitea-storage
              MINIO_USE_SSL: true
              MINIO_INSECURE_SKIP_VERIFY: false
              SERVE_DIRECT: true
            "storage.minio":
              STORAGE_TYPE: minio
              MINIO_ENDPOINT: s3.local.jazziro.com
              MINIO_LOCATION: joburg-north-1
              MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
              MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
              MINIO_BUCKET: gitea-storage
              MINIO_USE_SSL: true
              MINIO_INSECURE_SKIP_VERIFY: false
              SERVE_DIRECT: true
            database:
              DB_TYPE: postgres
              HOST: gitea-postgres-rw.gitea.svc.cluster.local:5432
              NAME: gitea
              USER: gitea
              PASSWD: gitea12345
          admin:
            # existingSecret: gitea-admin-secret
            existingSecret:
            username: root
            password: Gitea@homelab
            email: root@jazziro.com
            passwordMode: keepUpdated
        ingress:
          enabled: true
          className: "nginx"
          pathType: Prefix
          annotations: {}
          hosts:
            - host: git.jazziro.com
              paths:
                - path: /
          tls: []
          #  - secretName: chart-example-tls
          #    hosts:
          #      - git.example.com
    repoURL: https://dl.gitea.com/charts/
    targetRevision: 12.0.0
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T18:33:19Z"
    status: Progressing
  history:
  - deployStartedAt: "2025-07-07T18:33:17Z"
    deployedAt: "2025-07-07T18:33:19Z"
    id: 0
    initiatedBy:
      automated: true
    revisions:
    - 12.0.0
    source:
      repoURL: ""
    sources:
    - chart: gitea
      helm:
        releaseName: gitea
        values: |
          global:
            storageClass: "nfs-csi"
          postgresql:
            enabled: false
          postgresql-ha:
            enabled: false
          gitea:
            config:
              attachment:
                STORAGE_TYPE: minio
              lfs:
                STORAGE_TYPE: minio
              picture:
                AVATAR_STORAGE_TYPE: minio
              "storage.packages":
                STORAGE_TYPE: minio
              repo-avatars:
                STORAGE_TYPE: minio
              "storage":
                STORAGE_TYPE: minio
                MINIO_ENDPOINT: s3.local.jazziro.com
                MINIO_LOCATION: joburg-north-1
                MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                MINIO_BUCKET: gitea-storage
                MINIO_USE_SSL: true
                MINIO_INSECURE_SKIP_VERIFY: false
                SERVE_DIRECT: true
              "storage.minio":
                STORAGE_TYPE: minio
                MINIO_ENDPOINT: s3.local.jazziro.com
                MINIO_LOCATION: joburg-north-1
                MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                MINIO_BUCKET: gitea-storage
                MINIO_USE_SSL: true
                MINIO_INSECURE_SKIP_VERIFY: false
                SERVE_DIRECT: true
              database:
                DB_TYPE: postgres
                HOST: gitea-postgres-rw.gitea.svc.cluster.local:5432
                NAME: gitea
                USER: gitea
                PASSWD: gitea12345
            admin:
              # existingSecret: gitea-admin-secret
              existingSecret:
              username: root
              password: Gitea@homelab
              email: root@jazziro.com
              passwordMode: keepUpdated
          ingress:
            enabled: true
            className: "nginx"
            pathType: Prefix
            annotations: {}
            hosts:
              - host: git.jazziro.com
                paths:
                  - path: /
            tls: []
            #  - secretName: chart-example-tls
            #    hosts:
            #      - git.example.com
      repoURL: https://dl.gitea.com/charts/
      targetRevision: 12.0.0
  operationState:
    finishedAt: "2025-07-07T18:33:19Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revisions:
        - 12.0.0
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-07-07T18:33:17Z"
    syncResult:
      resources:
      - group: networking.k8s.io
        hookPhase: Running
        kind: NetworkPolicy
        message: networkpolicy.networking.k8s.io/gitea-valkey-cluster created
        name: gitea-valkey-cluster
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: policy
        hookPhase: Running
        kind: PodDisruptionBudget
        message: poddisruptionbudget.policy/gitea-valkey-cluster created
        name: gitea-valkey-cluster
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/gitea-valkey-cluster created
        name: gitea-valkey-cluster
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/gitea created
        name: gitea
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/gitea-inline-config created
        name: gitea-inline-config
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/gitea-init created
        name: gitea-init
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/gitea-valkey-cluster-scripts created
        name: gitea-valkey-cluster-scripts
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/gitea-valkey-cluster-default created
        name: gitea-valkey-cluster-default
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/gitea-shared-storage created
        name: gitea-shared-storage
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/gitea-ssh created
        name: gitea-ssh
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/gitea-valkey-cluster created
        name: gitea-valkey-cluster
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/gitea-valkey-cluster-headless created
        name: gitea-valkey-cluster-headless
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/gitea-http created
        name: gitea-http
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/gitea created
        name: gitea
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: StatefulSet
        message: statefulset.apps/gitea-valkey-cluster created
        name: gitea-valkey-cluster
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: networking.k8s.io
        hookPhase: Running
        kind: Ingress
        message: ingress.networking.k8s.io/gitea created
        name: gitea
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      revision: ""
      revisions:
      - 12.0.0
      source:
        repoURL: ""
      sources:
      - chart: gitea
        helm:
          releaseName: gitea
          values: |
            global:
              storageClass: "nfs-csi"
            postgresql:
              enabled: false
            postgresql-ha:
              enabled: false
            gitea:
              config:
                attachment:
                  STORAGE_TYPE: minio
                lfs:
                  STORAGE_TYPE: minio
                picture:
                  AVATAR_STORAGE_TYPE: minio
                "storage.packages":
                  STORAGE_TYPE: minio
                repo-avatars:
                  STORAGE_TYPE: minio
                "storage":
                  STORAGE_TYPE: minio
                  MINIO_ENDPOINT: s3.local.jazziro.com
                  MINIO_LOCATION: joburg-north-1
                  MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                  MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                  MINIO_BUCKET: gitea-storage
                  MINIO_USE_SSL: true
                  MINIO_INSECURE_SKIP_VERIFY: false
                  SERVE_DIRECT: true
                "storage.minio":
                  STORAGE_TYPE: minio
                  MINIO_ENDPOINT: s3.local.jazziro.com
                  MINIO_LOCATION: joburg-north-1
                  MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                  MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                  MINIO_BUCKET: gitea-storage
                  MINIO_USE_SSL: true
                  MINIO_INSECURE_SKIP_VERIFY: false
                  SERVE_DIRECT: true
                database:
                  DB_TYPE: postgres
                  HOST: gitea-postgres-rw.gitea.svc.cluster.local:5432
                  NAME: gitea
                  USER: gitea
                  PASSWD: gitea12345
              admin:
                # existingSecret: gitea-admin-secret
                existingSecret:
                username: root
                password: Gitea@homelab
                email: root@jazziro.com
                passwordMode: keepUpdated
            ingress:
              enabled: true
              className: "nginx"
              pathType: Prefix
              annotations: {}
              hosts:
                - host: git.jazziro.com
                  paths:
                    - path: /
              tls: []
              #  - secretName: chart-example-tls
              #    hosts:
              #      - git.example.com
        repoURL: https://dl.gitea.com/charts/
        targetRevision: 12.0.0
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ConfigMap
    name: gitea-valkey-cluster-default
    namespace: gitea
    status: Synced
    version: v1
  - kind: ConfigMap
    name: gitea-valkey-cluster-scripts
    namespace: gitea
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: gitea-shared-storage
    namespace: gitea
    status: Synced
    version: v1
  - kind: Secret
    name: gitea
    namespace: gitea
    status: Synced
    version: v1
  - kind: Secret
    name: gitea-init
    namespace: gitea
    status: Synced
    version: v1
  - kind: Secret
    name: gitea-inline-config
    namespace: gitea
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: gitea-http
    namespace: gitea
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: gitea-ssh
    namespace: gitea
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: gitea-valkey-cluster
    namespace: gitea
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: gitea-valkey-cluster-headless
    namespace: gitea
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: gitea-valkey-cluster
    namespace: gitea
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: gitea
    namespace: gitea
    status: Synced
    version: v1
  - group: apps
    health:
      message: 'partitioned roll out complete: 3 new pods have been updated...'
      status: Healthy
    kind: StatefulSet
    name: gitea-valkey-cluster
    namespace: gitea
    status: Synced
    version: v1
  - group: networking.k8s.io
    health:
      status: Progressing
    kind: Ingress
    name: gitea
    namespace: gitea
    status: Synced
    version: v1
  - group: networking.k8s.io
    kind: NetworkPolicy
    name: gitea-valkey-cluster
    namespace: gitea
    status: Synced
    version: v1
  - group: policy
    health:
      message: PodDisruptionBudget has SufficientPods
      status: Healthy
    kind: PodDisruptionBudget
    name: gitea-valkey-cluster
    namespace: gitea
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceTypes:
  - Helm
  summary:
    externalURLs:
    - http://git.jazziro.com/
    images:
    - docker.gitea.com/gitea:1.23.8-rootless
    - docker.io/bitnami/valkey-cluster:8.1.1-debian-12-r0
  sync:
    comparedTo:
      destination:
        namespace: gitea
        server: https://kubernetes.default.svc
      source:
        repoURL: ""
      sources:
      - chart: gitea
        helm:
          releaseName: gitea
          values: |
            global:
              storageClass: "nfs-csi"
            postgresql:
              enabled: false
            postgresql-ha:
              enabled: false
            gitea:
              config:
                attachment:
                  STORAGE_TYPE: minio
                lfs:
                  STORAGE_TYPE: minio
                picture:
                  AVATAR_STORAGE_TYPE: minio
                "storage.packages":
                  STORAGE_TYPE: minio
                repo-avatars:
                  STORAGE_TYPE: minio
                "storage":
                  STORAGE_TYPE: minio
                  MINIO_ENDPOINT: s3.local.jazziro.com
                  MINIO_LOCATION: joburg-north-1
                  MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                  MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                  MINIO_BUCKET: gitea-storage
                  MINIO_USE_SSL: true
                  MINIO_INSECURE_SKIP_VERIFY: false
                  SERVE_DIRECT: true
                "storage.minio":
                  STORAGE_TYPE: minio
                  MINIO_ENDPOINT: s3.local.jazziro.com
                  MINIO_LOCATION: joburg-north-1
                  MINIO_ACCESS_KEY_ID: cpuUbilo4MlxvDWTS13T
                  MINIO_SECRET_ACCESS_KEY: vjGMN2gpm7LQJXnRlpHjTkBTnXTOMcSvV0BdDvmF
                  MINIO_BUCKET: gitea-storage
                  MINIO_USE_SSL: true
                  MINIO_INSECURE_SKIP_VERIFY: false
                  SERVE_DIRECT: true
                database:
                  DB_TYPE: postgres
                  HOST: gitea-postgres-rw.gitea.svc.cluster.local:5432
                  NAME: gitea
                  USER: gitea
                  PASSWD: gitea12345
              admin:
                # existingSecret: gitea-admin-secret
                existingSecret:
                username: root
                password: Gitea@homelab
                email: root@jazziro.com
                passwordMode: keepUpdated
            ingress:
              enabled: true
              className: "nginx"
              pathType: Prefix
              annotations: {}
              hosts:
                - host: git.jazziro.com
                  paths:
                    - path: /
              tls: []
              #  - secretName: chart-example-tls
              #    hosts:
              #      - git.example.com
        repoURL: https://dl.gitea.com/charts/
        targetRevision: 12.0.0
    revisions:
    - 12.0.0
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: gitea-database
spec:
  destination:
    namespace: gitea
    server: https://kubernetes.default.svc
  ignoreDifferences:
  - group: postgresql.cnpg.io
    jsonPointers:
    - /spec/managed/roles
    kind: Cluster
  project: default
  source:
    path: kustomize/gitea-database/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T18:33:15Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-07T18:33:16Z"
    deployedAt: "2025-07-07T18:33:18Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
    source:
      path: kustomize/gitea-database/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: main
  operationState:
    finishedAt: "2025-07-07T18:33:18Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-07-07T18:33:16Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/gitea serverside-applied
        name: gitea
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/gitea-postgres-secrets serverside-applied
        name: gitea-postgres-secrets
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolume
        message: persistentvolume/gitea-postgres-data serverside-applied
        name: gitea-postgres-data
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      - group: postgresql.cnpg.io
        hookPhase: Running
        kind: Cluster
        message: cluster.postgresql.cnpg.io/gitea-postgres serverside-applied
        name: gitea-postgres
        namespace: gitea
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
      source:
        path: kustomize/gitea-database/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: PersistentVolume
    name: gitea-postgres-data
    status: Synced
    version: v1
  - kind: Secret
    name: gitea-postgres-secrets
    namespace: gitea
    status: Synced
    version: v1
  - group: postgresql.cnpg.io
    kind: Cluster
    name: gitea-postgres
    namespace: gitea
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Kustomize
  summary:
    images:
    - ghcr.io/cloudnative-pg/cloudnative-pg:1.25.1
    - ghcr.io/tensorchord/cloudnative-pgvecto.rs:16.5-v0.3.0@sha256:be3f025d79aa1b747817f478e07e71be43236e14d00d8a9eb3914146245035ba
  sync:
    comparedTo:
      destination:
        namespace: gitea
        server: https://kubernetes.default.svc
      ignoreDifferences:
      - group: postgresql.cnpg.io
        jsonPointers:
        - /spec/managed/roles
        kind: Cluster
      source:
        path: kustomize/gitea-database/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
    revision: 9757499c6f85d4922ff1f0c898f959d6fc13228b
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: gitea-runner
spec:
  destination:
    namespace: gitea
    server: https://kubernetes.default.svc
  project: default
  source:
    path: kustomize/gitea-runner/overlays/prod
    repoURL: https://git.jazziro.com/kubelab/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-08T02:22:43Z"
    message: |
      Failed to load target state: failed to generate manifest for source 1 of 1: rpc error: code = Unknown desc = failed to list refs: repository not found: Not found.
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T18:33:21Z"
    status: Healthy
  reconciledAt: "2025-07-08T20:01:44Z"
  sync:
    comparedTo:
      destination:
        namespace: gitea
        server: https://kubernetes.default.svc
      source:
        path: kustomize/gitea-runner/overlays/prod
        repoURL: https://git.jazziro.com/kubelab/kubelab.git
        targetRevision: main
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: goldilocks
spec:
  destination:
    namespace: goldilocks
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: goldilocks
    helm:
      releaseName: goldilocks
      values: |
        vpa:
          # vpa.enabled -- If true, the vpa will be installed as a sub-chart
          enabled: true
    repoURL: https://charts.fairwinds.com/stable
    targetRevision: 9.0.1
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T16:57:23Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-19T17:06:08Z"
    deployedAt: "2025-04-19T17:06:12Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 9.0.1
    source:
      chart: goldilocks
      helm:
        releaseName: goldilocks
        values: |
          vpa:
            # vpa.enabled -- If true, the vpa will be installed as a sub-chart
            enabled: false
      repoURL: https://charts.fairwinds.com/stable
      targetRevision: 9.0.1
  - deployStartedAt: "2025-04-19T17:21:37Z"
    deployedAt: "2025-04-19T17:23:20Z"
    id: 1
    initiatedBy:
      automated: true
    revision: 9.0.1
    source:
      chart: goldilocks
      helm:
        releaseName: goldilocks
        values: |
          vpa:
            # vpa.enabled -- If true, the vpa will be installed as a sub-chart
            enabled: true
      repoURL: https://charts.fairwinds.com/stable
      targetRevision: 9.0.1
  operationState:
    finishedAt: "2025-04-19T17:23:20Z"
    message: successfully synced (no more tasks)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 9.0.1
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-04-19T17:21:37Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Succeeded
        hookType: PreSync
        kind: ServiceAccount
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: ClusterRole
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: ClusterRoleBinding
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: Role
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: RoleBinding
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: batch
        hookPhase: Succeeded
        hookType: PreSync
        kind: Job
        message: job.batch/goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/goldilocks-vpa-recommender created
        name: goldilocks-vpa-recommender
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/goldilocks-vpa-admission-controller created
        name: goldilocks-vpa-admission-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/goldilocks-dashboard unchanged
        name: goldilocks-dashboard
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/goldilocks-controller unchanged
        name: goldilocks-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalercheckpoints.autoscaling.k8s.io
          created
        name: verticalpodautoscalercheckpoints.autoscaling.k8s.io
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalers.autoscaling.k8s.io
          created
        name: verticalpodautoscalers.autoscaling.k8s.io
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/goldilocks-dashboard reconciled.
          clusterrole.rbac.authorization.k8s.io/goldilocks-dashboard unchanged
        name: goldilocks-dashboard
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/goldilocks-controller reconciled.
          clusterrole.rbac.authorization.k8s.io/goldilocks-controller unchanged
        name: goldilocks-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-status-reader reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[coordination.k8s.io] Resources:[leases] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-status-reader
          configured. Warning: resource clusterroles/vpa-status-reader is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-status-reader
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-checkpoint-actor reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch create patch delete] APIGroups:[poc.autoscaling.k8s.io] Resources:[verticalpodautoscalercheckpoints]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch create
          patch delete] APIGroups:[autoscaling.k8s.io] Resources:[verticalpodautoscalercheckpoints]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list] APIGroups:[]
          Resources:[namespaces] ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-checkpoint-actor
          configured. Warning: resource clusterroles/vpa-checkpoint-actor is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-checkpoint-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-actor reconciled. reconciliation
          required create\n\tmissing rules added:\n\t\t{Verbs:[get list watch] APIGroups:[]
          Resources:[pods nodes limitranges] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch create] APIGroups:[] Resources:[events] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[poc.autoscaling.k8s.io] Resources:[verticalpodautoscalers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch patch]
          APIGroups:[autoscaling.k8s.io] Resources:[verticalpodautoscalers] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-actor configured.
          Warning: resource clusterroles/vpa-actor is missing the kubectl.kubernetes.io/last-applied-configuration
          annotation which is required by  apply.  apply should only be used on resources
          created declaratively by either  create --save-config or  apply. The missing
          annotation will be patched automatically."
        name: vpa-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-target-reader reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          watch] APIGroups:[*] Resources:[*/scale] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[replicationcontrollers] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[apps] Resources:[daemonsets
          deployments replicasets statefulsets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[batch] Resources:[jobs cronjobs] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-target-reader
          configured. Warning: resource clusterroles/vpa-target-reader is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-target-reader
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-admission-controller reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[pods configmaps nodes limitranges] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[create delete get list] APIGroups:[admissionregistration.k8s.io]
          Resources:[mutatingwebhookconfigurations] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[poc.autoscaling.k8s.io] Resources:[verticalpodautoscalers]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get list watch] APIGroups:[autoscaling.k8s.io]
          Resources:[verticalpodautoscalers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          update get list watch] APIGroups:[coordination.k8s.io] Resources:[leases]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-admission-controller
          configured. Warning: resource clusterroles/vpa-admission-controller is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-admission-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-status-actor reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          patch] APIGroups:[autoscaling.k8s.io] Resources:[verticalpodautoscalers/status]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/vpa-status-actor
          configured. Warning: resource clusterroles/vpa-status-actor is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-status-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-evictioner reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get]
          APIGroups:[apps extensions] Resources:[replicasets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create]
          APIGroups:[] Resources:[pods/eviction] ResourceNames:[] NonResourceURLs:[]}.
          clusterrole.rbac.authorization.k8s.io/vpa-evictioner configured. Warning:
          resource clusterroles/vpa-evictioner is missing the kubectl.kubernetes.io/last-applied-configuration
          annotation which is required by  apply.  apply should only be used on resources
          created declaratively by either  create --save-config or  apply. The missing
          annotation will be patched automatically."
        name: vpa-evictioner
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/vpa-metrics-reader reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list] APIGroups:[metrics.k8s.io] Resources:[pods] ResourceNames:[] NonResourceURLs:[]}.
          clusterrole.rbac.authorization.k8s.io/vpa-metrics-reader configured. Warning:
          resource clusterroles/vpa-metrics-reader is missing the kubectl.kubernetes.io/last-applied-configuration
          annotation which is required by  apply.  apply should only be used on resources
          created declaratively by either  create --save-config or  apply. The missing
          annotation will be patched automatically."
        name: vpa-metrics-reader
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/goldilocks-controller
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/goldilocks-controller
          unchanged
        name: goldilocks-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-metrics-reader
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-recommender Namespace:goldilocks}. clusterrolebinding.rbac.authorization.k8s.io/vpa-metrics-reader
          configured. Warning: resource clusterrolebindings/vpa-metrics-reader is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: vpa-metrics-reader
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/goldilocks-dashboard
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/goldilocks-dashboard
          unchanged
        name: goldilocks-dashboard
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-status-actor reconciled.
          reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-recommender Namespace:goldilocks}. clusterrolebinding.rbac.authorization.k8s.io/vpa-status-actor
          configured. Warning: resource clusterrolebindings/vpa-status-actor is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-status-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-target-reader-binding
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-recommender Namespace:goldilocks}\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-admission-controller Namespace:goldilocks}.
          clusterrolebinding.rbac.authorization.k8s.io/vpa-target-reader-binding configured.
          Warning: resource clusterrolebindings/vpa-target-reader-binding is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-target-reader-binding
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-checkpoint-actor
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-recommender Namespace:goldilocks}. clusterrolebinding.rbac.authorization.k8s.io/vpa-checkpoint-actor
          configured. Warning: resource clusterrolebindings/vpa-checkpoint-actor is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: vpa-checkpoint-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-actor reconciled.
          reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-recommender Namespace:goldilocks}. clusterrolebinding.rbac.authorization.k8s.io/vpa-actor
          configured. Warning: resource clusterrolebindings/vpa-actor is missing the
          kubectl.kubernetes.io/last-applied-configuration annotation which is required
          by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-actor
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/vpa-admission-controller
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:goldilocks-vpa-admission-controller Namespace:goldilocks}.
          clusterrolebinding.rbac.authorization.k8s.io/vpa-admission-controller configured.
          Warning: resource clusterrolebindings/vpa-admission-controller is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: vpa-admission-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/goldilocks-dashboard unchanged
        name: goldilocks-dashboard
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/goldilocks-vpa-webhook created
        name: goldilocks-vpa-webhook
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/goldilocks-vpa-admission-controller created
        name: goldilocks-vpa-admission-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/goldilocks-dashboard configured
        name: goldilocks-dashboard
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/goldilocks-vpa-recommender created
        name: goldilocks-vpa-recommender
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/goldilocks-controller configured
        name: goldilocks-controller
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: admissionregistration.k8s.io
        hookPhase: Succeeded
        kind: MutatingWebhookConfiguration
        message: mutatingwebhookconfiguration.admissionregistration.k8s.io/goldilocks-vpa-webhook-config
          created
        name: goldilocks-vpa-webhook-config
        namespace: goldilocks
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        hookType: PostSync
        kind: ServiceAccount
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: ClusterRole
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: ClusterRoleBinding
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: Role
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: RoleBinding
        message: goldilocks-vpa-admission-certgen created
        name: goldilocks-vpa-admission-certgen
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      - group: batch
        hookPhase: Succeeded
        hookType: PostSync
        kind: Job
        message: job.batch/goldilocks-vpa-admission-certgen-patch created
        name: goldilocks-vpa-admission-certgen-patch
        namespace: goldilocks
        syncPhase: PostSync
        version: v1
      revision: 9.0.1
      source:
        chart: goldilocks
        helm:
          releaseName: goldilocks
          values: |
            vpa:
              # vpa.enabled -- If true, the vpa will be installed as a sub-chart
              enabled: true
        repoURL: https://charts.fairwinds.com/stable
        targetRevision: 9.0.1
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: goldilocks-dashboard
    namespace: goldilocks
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: goldilocks-vpa-webhook
    namespace: goldilocks
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: goldilocks-controller
    namespace: goldilocks
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: goldilocks-dashboard
    namespace: goldilocks
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: goldilocks-vpa-admission-controller
    namespace: goldilocks
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: goldilocks-vpa-recommender
    namespace: goldilocks
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: MutatingWebhookConfiguration
    name: goldilocks-vpa-webhook-config
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: verticalpodautoscalercheckpoints.autoscaling.k8s.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: verticalpodautoscalers.autoscaling.k8s.io
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: goldilocks-controller
    namespace: goldilocks
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: goldilocks-dashboard
    namespace: goldilocks
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: goldilocks-vpa-admission-controller
    namespace: goldilocks
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: goldilocks-vpa-recommender
    namespace: goldilocks
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: goldilocks-controller
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: goldilocks-dashboard
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-admission-controller
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-checkpoint-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-evictioner
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-metrics-reader
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-status-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-status-reader
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: vpa-target-reader
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: goldilocks-controller
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: goldilocks-dashboard
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-admission-controller
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-checkpoint-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-metrics-reader
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-status-actor
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: vpa-target-reader-binding
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - registry.k8s.io/autoscaling/vpa-admission-controller:1.0.0
    - registry.k8s.io/autoscaling/vpa-recommender:1.0.0
    - us-docker.pkg.dev/fairwinds-ops/oss/goldilocks:v4.13.0
  sync:
    comparedTo:
      destination:
        namespace: goldilocks
        server: https://kubernetes.default.svc
      source:
        chart: goldilocks
        helm:
          releaseName: goldilocks
          values: |
            vpa:
              # vpa.enabled -- If true, the vpa will be installed as a sub-chart
              enabled: true
        repoURL: https://charts.fairwinds.com/stable
        targetRevision: 9.0.1
    revision: 9.0.1
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: headlamp
spec:
  destination:
    namespace: headlamp
    server: https://kubernetes.default.svc
  project: default
  sources:
  - chart: headlamp
    helm:
      releaseName: headlamp
      valueFiles:
      - $values/helm/headlamp_values.yaml
    repoURL: https://kubernetes-sigs.github.io/headlamp/
    targetRevision: 0.30.1
  - ref: values
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: develop
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-07T16:58:43Z"
    message: 'Failed to load target state: failed to generate manifest for source
      1 of 2: rpc error: code = Unknown desc = failed to get git client for repo https://github.com/codesenju/kubelab.git'
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-21T09:13:14Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-15T20:03:50Z"
    deployedAt: "2025-04-15T20:03:53Z"
    id: 0
    initiatedBy:
      automated: true
    revisions:
    - 0.30.1
    - 8e459072efcdefdace0702a310d68f8324c0f39d
    source:
      repoURL: ""
    sources:
    - chart: headlamp
      helm:
        releaseName: headlamp
        valueFiles:
        - $values/helm/headlamp_values.yaml
      repoURL: https://kubernetes-sigs.github.io/headlamp/
      targetRevision: 0.30.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-27T14:42:38Z"
    deployedAt: "2025-04-27T14:42:39Z"
    id: 1
    initiatedBy:
      automated: true
    revisions:
    - 0.30.1
    - a370fc42344e3f372f1b51f2226357216929a67c
    source:
      repoURL: ""
    sources:
    - chart: headlamp
      helm:
        releaseName: headlamp
        valueFiles:
        - $values/helm/headlamp_values.yaml
      repoURL: https://kubernetes-sigs.github.io/headlamp/
      targetRevision: 0.30.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-27T14:43:20Z"
    deployedAt: "2025-04-27T14:43:20Z"
    id: 2
    initiatedBy:
      username: codesenju@gmail.com
    revisions:
    - 0.30.1
    - a370fc42344e3f372f1b51f2226357216929a67c
    source:
      repoURL: ""
    sources:
    - chart: headlamp
      helm:
        releaseName: headlamp
        valueFiles:
        - $values/helm/headlamp_values.yaml
      repoURL: https://kubernetes-sigs.github.io/headlamp/
      targetRevision: 0.30.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-27T14:45:35Z"
    deployedAt: "2025-04-27T14:45:54Z"
    id: 3
    initiatedBy:
      username: codesenju@gmail.com
    revisions:
    - 0.30.1
    - 88adbf6ae6960017042b1c933459949cb92e6a7d
    source:
      repoURL: ""
    sources:
    - chart: headlamp
      helm:
        releaseName: headlamp
        valueFiles:
        - $values/helm/headlamp_values.yaml
      repoURL: https://kubernetes-sigs.github.io/headlamp/
      targetRevision: 0.30.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  operationState:
    finishedAt: "2025-04-27T14:45:56Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        autoHealAttemptsCount: 1
        prune: true
        resources:
        - kind: Secret
          name: oidc
        revisions:
        - 0.30.1
        - 88adbf6ae6960017042b1c933459949cb92e6a7d
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-04-27T14:45:56Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: pruned
        name: oidc
        namespace: headlamp
        status: Pruned
        syncPhase: Sync
        version: v1
      revision: ""
      revisions:
      - 0.30.1
      - 88adbf6ae6960017042b1c933459949cb92e6a7d
      source:
        repoURL: ""
      sources:
      - chart: headlamp
        helm:
          releaseName: headlamp
          valueFiles:
          - $values/helm/headlamp_values.yaml
        repoURL: https://kubernetes-sigs.github.io/headlamp/
        targetRevision: 0.30.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: development
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: headlamp
    namespace: headlamp
    requiresPruning: true
    status: Unknown
    version: v1
  - kind: ServiceAccount
    name: headlamp
    namespace: headlamp
    requiresPruning: true
    status: Unknown
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: headlamp
    namespace: headlamp
    requiresPruning: true
    status: Unknown
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: headlamp-admin
    requiresPruning: true
    status: Unknown
    version: v1
  sourceHydrator: {}
  summary:
    images:
    - ghcr.io/headlamp-k8s/headlamp:v0.30.0
  sync:
    comparedTo:
      destination:
        namespace: headlamp
        server: https://kubernetes.default.svc
      source:
        repoURL: ""
      sources:
      - chart: headlamp
        helm:
          releaseName: headlamp
          valueFiles:
          - $values/helm/headlamp_values.yaml
        repoURL: https://kubernetes-sigs.github.io/headlamp/
        targetRevision: 0.30.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: homarr
spec:
  destination:
    name: in-cluster
    namespace: homarr
  project: default
  source:
    chart: homarr
    helm:
      releaseName: homarr
      values: "rbac: \n  enabled: true\nservice:\n  # type: LoadBalancer\n  type:
        ClusterIP\n  # loadBalancerIP: 192.168.0.67\npersistence:\n  homarrDatabase:\n
        \   enabled: true\n    name: \"homarr-db\"\n    storageClassName: \"\"\n    size:
        \"50Mi\"\n    accessMode: \"ReadWriteOnce\"\n    volumeClaimName: \"homarr-db\"\n
        \ homarrImages:\n    enabled: true\n    name: \"homarr-images\"\n    storageClassName:
        \"\"\n    accessMode: \"ReadWriteOnce\"\n    size: \"50Mi\"\n    mountPath:
        \"/images\"\n    volumeClaimName: \"homarr-images\"\nenv:\n  NODE_TLS_REJECT_UNAUTHORIZED:
        0\n  TZ: Etc/GMT-2\n  AUTH_SESSION_EXPIRY_TIME: \"24h\"\n"
    repoURL: ghcr.io/homarr-labs/charts
    targetRevision: 3.7.1
  syncPolicy:
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-08T02:21:37Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-14T14:29:21Z"
    deployedAt: "2025-04-14T14:29:23Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 3.7.1
    source:
      chart: homarr
      helm:
        releaseName: homarr
        values: "rbac: \n  enabled: true\nservice:\n  # type: LoadBalancer\n  type:
          ClusterIP\n  # loadBalancerIP: 192.168.0.67\npersistence:\n  homarrDatabase:\n
          \   enabled: true\n    name: \"homarr-db\"\n    storageClassName: \"\"\n
          \   size: \"50Mi\"\n    accessMode: \"ReadWriteOnce\"\n    volumeClaimName:
          \"homarr-db\"\n  homarrImages:\n    enabled: true\n    name: \"homarr-images\"\n
          \   storageClassName: \"\"\n    accessMode: \"ReadWriteOnce\"\n    size:
          \"50Mi\"\n    mountPath: \"/images\"\n    volumeClaimName: \"homarr-images\"\nenv:\n
          \ NODE_TLS_REJECT_UNAUTHORIZED: 0\n  TZ: Etc/GMT-2\n  AUTH_SESSION_EXPIRY_TIME:
          \"24h\"\n"
      repoURL: ghcr.io/homarr-labs/charts
      targetRevision: 3.7.1
  - deployStartedAt: "2025-04-14T14:31:59Z"
    deployedAt: "2025-04-14T14:32:00Z"
    id: 1
    initiatedBy:
      username: codesenju@gmail.com
    revision: 3.7.1
    source:
      chart: homarr
      helm:
        releaseName: homarr
        values: "rbac: \n  enabled: true\nservice:\n  # type: LoadBalancer\n  type:
          ClusterIP\n  # loadBalancerIP: 192.168.0.67\npersistence:\n  homarrDatabase:\n
          \   enabled: true\n    name: \"homarr-db\"\n    storageClassName: \"\"\n
          \   size: \"50Mi\"\n    accessMode: \"ReadWriteOnce\"\n    volumeClaimName:
          \"homarr-db\"\n  homarrImages:\n    enabled: true\n    name: \"homarr-images\"\n
          \   storageClassName: \"\"\n    accessMode: \"ReadWriteOnce\"\n    size:
          \"50Mi\"\n    mountPath: \"/images\"\n    volumeClaimName: \"homarr-images\"\nenv:\n
          \ NODE_TLS_REJECT_UNAUTHORIZED: 0\n  TZ: Etc/GMT-2\n  AUTH_SESSION_EXPIRY_TIME:
          \"24h\"\n"
      repoURL: ghcr.io/homarr-labs/charts
      targetRevision: 3.7.1
  operationState:
    finishedAt: "2025-04-14T14:39:01Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: codesenju@gmail.com
      retry: {}
      sync:
        resources:
        - kind: PersistentVolumeClaim
          name: homarr-images
          namespace: homarr
        revision: 3.7.1
        syncOptions:
        - CreateNamespace=true
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2025-04-14T14:39:00Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/homarr-images created
        name: homarr-images
        namespace: homarr
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 3.7.1
      source:
        chart: homarr
        helm:
          releaseName: homarr
          values: "rbac: \n  enabled: true\nservice:\n  # type: LoadBalancer\n  type:
            ClusterIP\n  # loadBalancerIP: 192.168.0.67\npersistence:\n  homarrDatabase:\n
            \   enabled: true\n    name: \"homarr-db\"\n    storageClassName: \"\"\n
            \   size: \"50Mi\"\n    accessMode: \"ReadWriteOnce\"\n    volumeClaimName:
            \"homarr-db\"\n  homarrImages:\n    enabled: true\n    name: \"homarr-images\"\n
            \   storageClassName: \"\"\n    accessMode: \"ReadWriteOnce\"\n    size:
            \"50Mi\"\n    mountPath: \"/images\"\n    volumeClaimName: \"homarr-images\"\nenv:\n
            \ NODE_TLS_REJECT_UNAUTHORIZED: 0\n  TZ: Etc/GMT-2\n  AUTH_SESSION_EXPIRY_TIME:
            \"24h\"\n"
        repoURL: ghcr.io/homarr-labs/charts
        targetRevision: 3.7.1
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: homarr-db
    namespace: homarr
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: homarr-images
    namespace: homarr
    status: Synced
    version: v1
  - kind: Secret
    name: homarr-sa-token
    namespace: homarr
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: homarr
    namespace: homarr
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: homarr-sa
    namespace: homarr
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: homarr
    namespace: homarr
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: homarr-cluster-role
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: homarr-cluster-rolebinding
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: homarr-role
    namespace: homarr
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: homarr-rolebinding
    namespace: homarr
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - ghcr.io/homarr-labs/homarr:v1.16.0
  sync:
    comparedTo:
      destination:
        name: in-cluster
        namespace: homarr
      source:
        chart: homarr
        helm:
          releaseName: homarr
          values: "rbac: \n  enabled: true\nservice:\n  # type: LoadBalancer\n  type:
            ClusterIP\n  # loadBalancerIP: 192.168.0.67\npersistence:\n  homarrDatabase:\n
            \   enabled: true\n    name: \"homarr-db\"\n    storageClassName: \"\"\n
            \   size: \"50Mi\"\n    accessMode: \"ReadWriteOnce\"\n    volumeClaimName:
            \"homarr-db\"\n  homarrImages:\n    enabled: true\n    name: \"homarr-images\"\n
            \   storageClassName: \"\"\n    accessMode: \"ReadWriteOnce\"\n    size:
            \"50Mi\"\n    mountPath: \"/images\"\n    volumeClaimName: \"homarr-images\"\nenv:\n
            \ NODE_TLS_REJECT_UNAUTHORIZED: 0\n  TZ: Etc/GMT-2\n  AUTH_SESSION_EXPIRY_TIME:
            \"24h\"\n"
        repoURL: ghcr.io/homarr-labs/charts
        targetRevision: 3.7.1
    revision: 3.7.1
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: immich-postgres
spec:
  destination:
    namespace: immich
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    path: kustomize/immich-postgres/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: develop
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-07T16:57:22Z"
    message: 'Failed to load target state: failed to generate manifest for source
      1 of 1: rpc error: code = Unknown desc = unable to resolve ''develop'' to a
      commit SHA'
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-21T22:52:52Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-05-21T22:52:52Z"
    deployedAt: "2025-05-21T22:52:52Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 32e5a994acbb3e59bf42314626fdfcd95e7e48d0
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      path: kustomize/immich-postgres/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: develop
  - deployStartedAt: "2025-05-24T19:21:26Z"
    deployedAt: "2025-05-24T19:21:26Z"
    id: 1
    initiatedBy:
      automated: true
    revision: fbb625271aed9da0c591d489f35c8afb42b3028c
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      path: kustomize/immich-postgres/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: develop
  - deployStartedAt: "2025-05-24T19:39:26Z"
    deployedAt: "2025-05-24T19:39:26Z"
    id: 2
    initiatedBy:
      automated: true
    revision: 5def4c18698cb7dbf1952d57b476a9d927de19dd
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      path: kustomize/immich-postgres/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: develop
  operationState:
    finishedAt: "2025-06-03T13:21:10Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        autoHealAttemptsCount: 2807
        prune: true
        resources:
        - group: postgresql.cnpg.io
          kind: Cluster
          name: immich-postgres
        revision: 5def4c18698cb7dbf1952d57b476a9d927de19dd
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-06-03T13:21:10Z"
    syncResult:
      resources:
      - group: postgresql.cnpg.io
        hookPhase: Running
        kind: Cluster
        message: cluster.postgresql.cnpg.io/immich-postgres serverside-applied
        name: immich-postgres
        namespace: immich
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 5def4c18698cb7dbf1952d57b476a9d927de19dd
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        path: kustomize/immich-postgres/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: PersistentVolume
    name: immich-postgres-data
    requiresPruning: true
    status: Unknown
    version: v1
  - kind: Secret
    name: immich-postgres-user
    namespace: immich
    requiresPruning: true
    status: Unknown
    version: v1
  - group: postgresql.cnpg.io
    kind: Cluster
    name: immich-postgres
    namespace: immich
    requiresPruning: true
    status: Unknown
    version: v1
  sourceHydrator: {}
  summary:
    images:
    - ghcr.io/cloudnative-pg/cloudnative-pg:1.25.1
    - ghcr.io/tensorchord/cloudnative-pgvecto.rs:16.5-v0.3.0@sha256:be3f025d79aa1b747817f478e07e71be43236e14d00d8a9eb3914146245035ba
  sync:
    comparedTo:
      destination:
        namespace: immich
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        path: kustomize/immich-postgres/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: kube-prometheus-stack
spec:
  destination:
    namespace: kube-prometheus-stack
    server: https://kubernetes.default.svc
  project: default
  sources:
  - chart: kube-prometheus-stack
    helm:
      releaseName: kube-prometheus-stack
      valueFiles:
      - $values/helm/kube_prometheus_stack_values.yaml
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: 70.4.1
  - ref: values
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T18:20:35Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-07T18:19:03Z"
    deployedAt: "2025-07-07T18:21:13Z"
    id: 0
    initiatedBy:
      automated: true
    revisions:
    - 70.4.1
    - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
    source:
      repoURL: ""
    sources:
    - chart: kube-prometheus-stack
      helm:
        releaseName: kube-prometheus-stack
        valueFiles:
        - $values/helm/kube_prometheus_stack_values.yaml
      repoURL: https://prometheus-community.github.io/helm-charts
      targetRevision: 70.4.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: main
  operationState:
    finishedAt: "2025-07-07T18:21:13Z"
    message: successfully synced (no more tasks)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revisions:
        - 70.4.1
        - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    retryCount: 2
    startedAt: "2025-07-07T18:19:03Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Succeeded
        hookType: PreSync
        kind: ServiceAccount
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: ClusterRole
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: ClusterRoleBinding
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: Role
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PreSync
        kind: RoleBinding
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: batch
        hookPhase: Succeeded
        hookType: PreSync
        kind: Job
        message: Reached expected number of succeeded pods
        name: kube-prometheus-stack-admission-create
        namespace: kube-prometheus-stack
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-operator serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-kube-state-metrics serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-prometheus-node-exporter serverside-applied
        name: kube-prometheus-stack-prometheus-node-exporter
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-alertmanager serverside-applied
        name: kube-prometheus-stack-alertmanager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-prometheus serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/kube-prometheus-stack-thanos-ruler serverside-applied
        name: kube-prometheus-stack-thanos-ruler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: secret/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: secret/alertmanager-kube-prometheus-stack-alertmanager serverside-applied
        name: alertmanager-kube-prometheus-stack-alertmanager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Secret
        message: secret/kube-prometheus-stack-thanos-ruler serverside-applied
        name: kube-prometheus-stack-thanos-ruler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-etcd serverside-applied
        name: kube-prometheus-stack-etcd
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-pod serverside-applied
        name: kube-prometheus-stack-k8s-resources-pod
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-nodes-aix serverside-applied
        name: kube-prometheus-stack-nodes-aix
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-cluster serverside-applied
        name: kube-prometheus-stack-k8s-resources-cluster
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-alertmanager-overview serverside-applied
        name: kube-prometheus-stack-alertmanager-overview
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-apiserver serverside-applied
        name: kube-prometheus-stack-apiserver
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-coredns serverside-applied
        name: kube-prometheus-stack-k8s-coredns
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-node-cluster-rsrc-use serverside-applied
        name: kube-prometheus-stack-node-cluster-rsrc-use
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-namespace-by-pod serverside-applied
        name: kube-prometheus-stack-namespace-by-pod
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-namespace-by-workload serverside-applied
        name: kube-prometheus-stack-namespace-by-workload
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-node-rsrc-use serverside-applied
        name: kube-prometheus-stack-node-rsrc-use
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-cluster-total serverside-applied
        name: kube-prometheus-stack-cluster-total
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-persistentvolumesusage serverside-applied
        name: kube-prometheus-stack-persistentvolumesusage
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-workloads-namespace
          serverside-applied
        name: kube-prometheus-stack-k8s-resources-workloads-namespace
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-namespace serverside-applied
        name: kube-prometheus-stack-k8s-resources-namespace
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-controller-manager serverside-applied
        name: kube-prometheus-stack-controller-manager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-nodes-darwin serverside-applied
        name: kube-prometheus-stack-nodes-darwin
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-multicluster serverside-applied
        name: kube-prometheus-stack-k8s-resources-multicluster
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-nodes serverside-applied
        name: kube-prometheus-stack-nodes
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-kubelet serverside-applied
        name: kube-prometheus-stack-kubelet
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-workload serverside-applied
        name: kube-prometheus-stack-k8s-resources-workload
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-grafana-config-dashboards serverside-applied
        name: kube-prometheus-stack-grafana-config-dashboards
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-scheduler serverside-applied
        name: kube-prometheus-stack-scheduler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-grafana-datasource serverside-applied
        name: kube-prometheus-stack-grafana-datasource
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-prometheus serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-proxy serverside-applied
        name: kube-prometheus-stack-proxy
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-pod-total serverside-applied
        name: kube-prometheus-stack-pod-total
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-grafana-overview serverside-applied
        name: kube-prometheus-stack-grafana-overview
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-k8s-resources-node serverside-applied
        name: kube-prometheus-stack-k8s-resources-node
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: ConfigMap
        message: configmap/kube-prometheus-stack-workload-total serverside-applied
        name: kube-prometheus-stack-workload-total
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com
          serverside-applied
        name: prometheusrules.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com
          serverside-applied
        name: probes.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com
          serverside-applied
        name: servicemonitors.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com
          serverside-applied
        name: podmonitors.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com
          serverside-applied
        name: thanosrulers.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com
          serverside-applied
        name: alertmanagerconfigs.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com
          serverside-applied
        name: alertmanagers.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/prometheusagents.monitoring.coreos.com
          serverside-applied
        name: prometheusagents.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/scrapeconfigs.monitoring.coreos.com
          serverside-applied
        name: scrapeconfigs.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com
          serverside-applied
        name: prometheuses.monitoring.coreos.com
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-grafana-clusterrole
          reconciled. clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-grafana-clusterrole
          serverside-applied
        name: kube-prometheus-stack-grafana-clusterrole
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-kube-state-metrics
          reconciled. clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-kube-state-metrics
          serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-operator
          reconciled. clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-operator
          serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-prometheus
          reconciled. clusterrole.rbac.authorization.k8s.io/kube-prometheus-stack-prometheus
          serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-grafana-clusterrolebinding
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-grafana-clusterrolebinding
          serverside-applied
        name: kube-prometheus-stack-grafana-clusterrolebinding
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-kube-state-metrics
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-kube-state-metrics
          serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-operator
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-operator
          serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-prometheus
          reconciled. clusterrolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-prometheus
          serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: Role
        message: role.rbac.authorization.k8s.io/kube-prometheus-stack-grafana reconciled.
          role.rbac.authorization.k8s.io/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: RoleBinding
        message: rolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-grafana
          reconciled. rolebinding.rbac.authorization.k8s.io/kube-prometheus-stack-grafana
          serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-alertmanager serverside-applied
        name: kube-prometheus-stack-alertmanager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-operator serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-thanos-ruler serverside-applied
        name: kube-prometheus-stack-thanos-ruler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-kube-etcd serverside-applied
        name: kube-prometheus-stack-kube-etcd
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-prometheus-node-exporter serverside-applied
        name: kube-prometheus-stack-prometheus-node-exporter
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-kube-scheduler serverside-applied
        name: kube-prometheus-stack-kube-scheduler
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-kube-proxy serverside-applied
        name: kube-prometheus-stack-kube-proxy
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-kube-controller-manager serverside-applied
        name: kube-prometheus-stack-kube-controller-manager
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-kube-state-metrics serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-thanos-discovery serverside-applied
        name: kube-prometheus-stack-thanos-discovery
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-prometheus serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/kube-prometheus-stack-coredns serverside-applied
        name: kube-prometheus-stack-coredns
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: DaemonSet
        message: daemonset.apps/kube-prometheus-stack-prometheus-node-exporter serverside-applied
        name: kube-prometheus-stack-prometheus-node-exporter
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/kube-prometheus-stack-kube-state-metrics serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/kube-prometheus-stack-operator serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/kube-prometheus-stack-grafana serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: admissionregistration.k8s.io
        hookPhase: Succeeded
        kind: ValidatingWebhookConfiguration
        message: validatingwebhookconfiguration.admissionregistration.k8s.io/kube-prometheus-stack-admission
          serverside-applied
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: admissionregistration.k8s.io
        hookPhase: Succeeded
        kind: MutatingWebhookConfiguration
        message: mutatingwebhookconfiguration.admissionregistration.k8s.io/kube-prometheus-stack-admission
          serverside-applied
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-alertmanager
          serverside-applied
        name: kube-prometheus-stack-alertmanager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: Alertmanager
        message: alertmanager.monitoring.coreos.com/kube-prometheus-stack-alertmanager
          serverside-applied
        name: kube-prometheus-stack-alertmanager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-alertmanager.rules
          serverside-applied
        name: kube-prometheus-stack-alertmanager.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-apiserver
          serverside-applied
        name: kube-prometheus-stack-apiserver
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-config-reloaders
          serverside-applied
        name: kube-prometheus-stack-config-reloaders
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-coredns
          serverside-applied
        name: kube-prometheus-stack-coredns
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-general.rules
          serverside-applied
        name: kube-prometheus-stack-general.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-etcd serverside-applied
        name: kube-prometheus-stack-etcd
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-grafana
          serverside-applied
        name: kube-prometheus-stack-grafana
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-cpu-usage-seconds-tot
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-cpu-usage-seconds-tot
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-apiserver-availability.rules
          serverside-applied
        name: kube-prometheus-stack-kube-apiserver-availability.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-apiserver-burnrate.rules
          serverside-applied
        name: kube-prometheus-stack-kube-apiserver-burnrate.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-apiserver-slos
          serverside-applied
        name: kube-prometheus-stack-kube-apiserver-slos
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-memory-cache
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-memory-cache
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-memory-swap
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-memory-swap
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-apiserver-histogram.rules
          serverside-applied
        name: kube-prometheus-stack-kube-apiserver-histogram.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-resource
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-resource
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-memory-working-set-by
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-memory-working-set-by
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.container-memory-rss
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.container-memory-rss
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-k8s.rules.pod-owner
          serverside-applied
        name: kube-prometheus-stack-k8s.rules.pod-owner
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kube-controller-manager
          serverside-applied
        name: kube-prometheus-stack-kube-controller-manager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kube-etcd
          serverside-applied
        name: kube-prometheus-stack-kube-etcd
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-prometheus-general.rules
          serverside-applied
        name: kube-prometheus-stack-kube-prometheus-general.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-prometheus-node-recording.rules
          serverside-applied
        name: kube-prometheus-stack-kube-prometheus-node-recording.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kube-proxy
          serverside-applied
        name: kube-prometheus-stack-kube-proxy
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kube-scheduler
          serverside-applied
        name: kube-prometheus-stack-kube-scheduler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-scheduler.rules
          serverside-applied
        name: kube-prometheus-stack-kube-scheduler.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kube-state-metrics
          serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kube-state-metrics
          serverside-applied
        name: kube-prometheus-stack-kube-state-metrics
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-kubelet
          serverside-applied
        name: kube-prometheus-stack-kubelet
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system-kubelet
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system-kubelet
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubelet.rules
          serverside-applied
        name: kube-prometheus-stack-kubelet.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system-controller-manager
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system-controller-manager
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system-apiserver
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system-apiserver
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system-kube-proxy
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system-kube-proxy
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-node.rules
          serverside-applied
        name: kube-prometheus-stack-node.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-node-exporter
          serverside-applied
        name: kube-prometheus-stack-node-exporter
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-node-exporter.rules
          serverside-applied
        name: kube-prometheus-stack-node-exporter.rules
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-storage
          serverside-applied
        name: kube-prometheus-stack-kubernetes-storage
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system-scheduler
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system-scheduler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-node-network
          serverside-applied
        name: kube-prometheus-stack-node-network
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-apps
          serverside-applied
        name: kube-prometheus-stack-kubernetes-apps
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-resources
          serverside-applied
        name: kube-prometheus-stack-kubernetes-resources
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-kubernetes-system
          serverside-applied
        name: kube-prometheus-stack-kubernetes-system
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-operator
          serverside-applied
        name: kube-prometheus-stack-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: Prometheus
        message: All instances are available
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-prometheus
          serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-prometheus
          serverside-applied
        name: kube-prometheus-stack-prometheus
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-prometheus-node-exporter
          serverside-applied
        name: kube-prometheus-stack-prometheus-node-exporter
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: PrometheusRule
        message: prometheusrule.monitoring.coreos.com/kube-prometheus-stack-prometheus-operator
          serverside-applied
        name: kube-prometheus-stack-prometheus-operator
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ThanosRuler
        message: thanosruler.monitoring.coreos.com/kube-prometheus-stack-thanos-ruler
          serverside-applied
        name: kube-prometheus-stack-thanos-ruler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-thanos-ruler
          serverside-applied
        name: kube-prometheus-stack-thanos-ruler
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: monitoring.coreos.com
        hookPhase: Succeeded
        kind: ServiceMonitor
        message: servicemonitor.monitoring.coreos.com/kube-prometheus-stack-thanos-sidecar
          serverside-applied
        name: kube-prometheus-stack-thanos-sidecar
        namespace: kube-prometheus-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        hookType: PostSync
        kind: ServiceAccount
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: ClusterRole
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: ClusterRoleBinding
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: Role
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        hookType: PostSync
        kind: RoleBinding
        message: kube-prometheus-stack-admission created
        name: kube-prometheus-stack-admission
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      - group: batch
        hookPhase: Succeeded
        hookType: PostSync
        kind: Job
        message: Reached expected number of succeeded pods
        name: kube-prometheus-stack-admission-patch
        namespace: kube-prometheus-stack
        syncPhase: PostSync
        version: v1
      revision: ""
      revisions:
      - 70.4.1
      - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
      source:
        repoURL: ""
      sources:
      - chart: kube-prometheus-stack
        helm:
          releaseName: kube-prometheus-stack
          valueFiles:
          - $values/helm/kube_prometheus_stack_values.yaml
        repoURL: https://prometheus-community.github.io/helm-charts
        targetRevision: 70.4.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ConfigMap
    name: kube-prometheus-stack-alertmanager-overview
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-apiserver
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-cluster-total
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-controller-manager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-etcd
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-grafana-config-dashboards
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-grafana-datasource
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-grafana-overview
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-coredns
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-cluster
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-multicluster
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-namespace
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-node
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-pod
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-workload
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-k8s-resources-workloads-namespace
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-kubelet
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-namespace-by-pod
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-namespace-by-workload
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-node-cluster-rsrc-use
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-node-rsrc-use
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-nodes
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-nodes-aix
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-nodes-darwin
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-persistentvolumesusage
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-pod-total
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-proxy
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-scheduler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: kube-prometheus-stack-workload-total
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: Secret
    name: alertmanager-kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: Secret
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: Secret
    name: kube-prometheus-stack-thanos-ruler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-thanos-discovery
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-thanos-ruler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-coredns
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-kube-controller-manager
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-kube-etcd
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-kube-proxy
    namespace: kube-system
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: kube-prometheus-stack-kube-scheduler
    namespace: kube-system
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: kube-prometheus-stack-thanos-ruler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: MutatingWebhookConfiguration
    name: kube-prometheus-stack-admission
    status: Synced
    version: v1
  - group: admissionregistration.k8s.io
    kind: ValidatingWebhookConfiguration
    name: kube-prometheus-stack-admission
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: alertmanagerconfigs.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: alertmanagers.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: podmonitors.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: probes.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: prometheusagents.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: prometheuses.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: prometheusrules.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: scrapeconfigs.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: servicemonitors.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: thanosrulers.monitoring.coreos.com
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: DaemonSet
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: Alertmanager
    name: kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    health:
      message: All instances are available
      status: Healthy
    kind: Prometheus
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-alertmanager.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-config-reloaders
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-etcd
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-general.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-cpu-usage-seconds-tot
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-memory-cache
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-memory-rss
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-memory-swap
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-memory-working-set-by
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.container-resource
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-k8s.rules.pod-owner
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-apiserver-availability.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-apiserver-burnrate.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-apiserver-histogram.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-apiserver-slos
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-prometheus-general.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-prometheus-node-recording.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-scheduler.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubelet.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-apps
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-resources
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-storage
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system-apiserver
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system-controller-manager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system-kube-proxy
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system-kubelet
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-kubernetes-system-scheduler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-node-exporter
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-node-exporter.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-node-network
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-node.rules
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: PrometheusRule
    name: kube-prometheus-stack-prometheus-operator
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-apiserver
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-coredns
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kube-controller-manager
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kube-etcd
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kube-proxy
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kube-scheduler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-kubelet
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-thanos-ruler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ServiceMonitor
    name: kube-prometheus-stack-thanos-sidecar
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: monitoring.coreos.com
    kind: ThanosRuler
    name: kube-prometheus-stack-thanos-ruler
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kube-prometheus-stack-grafana-clusterrole
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kube-prometheus-stack-kube-state-metrics
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kube-prometheus-stack-operator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kube-prometheus-stack-prometheus
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: kube-prometheus-stack-grafana-clusterrolebinding
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: kube-prometheus-stack-kube-state-metrics
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: kube-prometheus-stack-operator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: kube-prometheus-stack-prometheus
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: Role
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceTypes:
  - Helm
  - ""
  summary:
    images:
    - docker.io/grafana/grafana:11.6.0
    - quay.io/kiwigrid/k8s-sidecar:1.30.0
    - quay.io/prometheus-operator/prometheus-config-reloader:v0.81.0
    - quay.io/prometheus-operator/prometheus-operator:v0.81.0
    - quay.io/prometheus/alertmanager:v0.28.1
    - quay.io/prometheus/node-exporter:v1.9.0
    - quay.io/prometheus/prometheus:v3.2.1
    - quay.io/thanos/thanos:v0.37.2
    - registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0
  sync:
    comparedTo:
      destination:
        namespace: kube-prometheus-stack
        server: https://kubernetes.default.svc
      source:
        repoURL: ""
      sources:
      - chart: kube-prometheus-stack
        helm:
          releaseName: kube-prometheus-stack
          valueFiles:
          - $values/helm/kube_prometheus_stack_values.yaml
        repoURL: https://prometheus-community.github.io/helm-charts
        targetRevision: 70.4.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
    revisions:
    - 70.4.1
    - 9757499c6f85d4922ff1f0c898f959d6fc13228b
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: media-stack
spec:
  destination:
    namespace: media-stack
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      commonLabels:
        app.kubernetes.io/instance: media-stack-prod
    path: kustomize/media-stack/overlays/production
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T17:56:23Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-15T18:20:49Z"
    deployedAt: "2025-04-15T18:20:52Z"
    id: 45
    initiatedBy:
      username: codesenju@gmail.com
    revision: 6446118ed04401709f868be50dd0c17985c897db
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-16T07:20:04Z"
    deployedAt: "2025-04-16T07:20:09Z"
    id: 46
    initiatedBy:
      username: codesenju@gmail.com
    revision: 74722d769a4f6f684f9a9ab77fb7cfe99b795aca
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-16T07:22:17Z"
    deployedAt: "2025-04-16T07:22:18Z"
    id: 47
    initiatedBy:
      username: codesenju@gmail.com
    revision: 74722d769a4f6f684f9a9ab77fb7cfe99b795aca
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-16T07:23:23Z"
    deployedAt: "2025-04-16T07:23:27Z"
    id: 48
    initiatedBy:
      username: codesenju@gmail.com
    revision: 141c889064b821c602797364b91950a6a64c6c8a
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-16T07:23:34Z"
    deployedAt: "2025-04-16T07:23:36Z"
    id: 49
    initiatedBy:
      username: codesenju@gmail.com
    revision: 141c889064b821c602797364b91950a6a64c6c8a
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-04-16T07:24:07Z"
    deployedAt: "2025-04-16T07:24:11Z"
    id: 50
    initiatedBy:
      username: codesenju@gmail.com
    revision: c1e891e09262ac715b5154c8f53ba35eabf678de
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  - deployStartedAt: "2025-05-18T12:40:24Z"
    deployedAt: "2025-05-18T12:40:25Z"
    id: 51
    initiatedBy:
      automated: true
    revision: 93da96b75340882e154e4feb99d9ec5a1641b30a
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: develop
  - deployStartedAt: "2025-05-24T19:21:26Z"
    deployedAt: "2025-05-24T19:21:27Z"
    id: 52
    initiatedBy:
      automated: true
    revision: fbb625271aed9da0c591d489f35c8afb42b3028c
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: develop
  - deployStartedAt: "2025-07-07T17:55:52Z"
    deployedAt: "2025-07-07T17:55:53Z"
    id: 53
    initiatedBy:
      automated: true
    revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: main
  - deployStartedAt: "2025-07-07T17:58:22Z"
    deployedAt: "2025-07-07T17:58:23Z"
    id: 54
    initiatedBy:
      username: admin
    revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: media-stack-prod
      path: kustomize/media-stack/overlays/production
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: main
  operationState:
    finishedAt: "2025-07-07T17:58:23Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
        syncStrategy:
          hook: {}
    phase: Succeeded
    startedAt: "2025-07-07T17:58:22Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: ResourceQuota
        message: resourcequota/media-stack-resource-quota serverside-applied
        name: media-stack-resource-quota
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: LimitRange
        message: limitrange/media-stack-resource-limits serverside-applied
        name: media-stack-resource-limits
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/shared-permissions serverside-applied
        name: shared-permissions
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/global-env-66d8mmhtt8 serverside-applied
        name: global-env-66d8mmhtt8
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ConfigMap
        message: configmap/media-stack-env-9dm466b9bh serverside-applied
        name: media-stack-env-9dm466b9bh
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolume
        message: persistentvolume/media-data serverside-applied
        name: media-data
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolume
        message: persistentvolume/media-stack-config serverside-applied
        name: media-stack-config
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/media-stack-config serverside-applied
        name: media-stack-config
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/media-data serverside-applied
        name: media-data
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/radarr serverside-applied
        name: radarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/lidarr serverside-applied
        name: lidarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/prowlarr serverside-applied
        name: prowlarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jellyfin serverside-applied
        name: jellyfin
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/tdarr serverside-applied
        name: tdarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/jellyseerr serverside-applied
        name: jellyseerr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/sonarr serverside-applied
        name: sonarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/flaresolverr serverside-applied
        name: flaresolverr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/readarr serverside-applied
        name: readarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/jellyseerr serverside-applied
        name: jellyseerr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/radarr serverside-applied
        name: radarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/jellyfin serverside-applied
        name: jellyfin
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/tdarr serverside-applied
        name: tdarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/prowlarr serverside-applied
        name: prowlarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/flaresolverr serverside-applied
        name: flaresolverr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/sonarr serverside-applied
        name: sonarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/readarr serverside-applied
        name: readarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/lidarr serverside-applied
        name: lidarr
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/tdarr-worker serverside-applied
        name: tdarr-worker
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: scheduling.k8s.io
        hookPhase: Running
        kind: PriorityClass
        message: priorityclass.scheduling.k8s.io/high-priority serverside-applied
        name: high-priority
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      - group: scheduling.k8s.io
        hookPhase: Running
        kind: PriorityClass
        message: priorityclass.scheduling.k8s.io/default-priority serverside-applied
        name: default-priority
        namespace: media-stack
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 14e8e94cfc5fefc3865348ab19b8d4186d97d549
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: media-stack-prod
        path: kustomize/media-stack/overlays/production
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: ConfigMap
    name: global-env-66d8mmhtt8
    namespace: media-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: media-stack-env-9dm466b9bh
    namespace: media-stack
    status: Synced
    version: v1
  - kind: ConfigMap
    name: shared-permissions
    namespace: media-stack
    status: Synced
    version: v1
  - kind: LimitRange
    name: media-stack-resource-limits
    namespace: media-stack
    status: Synced
    version: v1
  - kind: PersistentVolume
    name: media-data
    status: Synced
    version: v1
  - kind: PersistentVolume
    name: media-stack-config
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: media-data
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: media-stack-config
    namespace: media-stack
    status: Synced
    version: v1
  - kind: ResourceQuota
    name: media-stack-resource-quota
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: flaresolverr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: jellyfin
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: jellyseerr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: lidarr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: prowlarr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: radarr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: readarr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: sonarr
    namespace: media-stack
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: tdarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: flaresolverr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: jellyfin
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: jellyseerr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: lidarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: prowlarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: radarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: readarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: sonarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: tdarr
    namespace: media-stack
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: tdarr-worker
    namespace: media-stack
    status: Synced
    version: v1
  - group: scheduling.k8s.io
    kind: PriorityClass
    name: default-priority
    status: Synced
    version: v1
  - group: scheduling.k8s.io
    kind: PriorityClass
    name: high-priority
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Kustomize
  summary:
    images:
    - docker.io/fallenbagel/jellyseerr:2.5.2
    - ghcr.io/flaresolverr/flaresolverr:v3.3.21
    - ghcr.io/haveagitgat/tdarr:2.37.01
    - ghcr.io/haveagitgat/tdarr_node:2.37.01
    - lscr.io/linuxserver/jellyfin:10.10.7
    - lscr.io/linuxserver/lidarr:2.10.3
    - lscr.io/linuxserver/prowlarr:1.33.3
    - lscr.io/linuxserver/radarr:5.21.1
    - lscr.io/linuxserver/readarr:develop-version-0.4.14.2782
    - lscr.io/linuxserver/sonarr:4.0.14
  sync:
    comparedTo:
      destination:
        namespace: media-stack
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: media-stack-prod
        path: kustomize/media-stack/overlays/production
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
    revision: 9757499c6f85d4922ff1f0c898f959d6fc13228b
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: metrics-server
spec:
  destination:
    namespace: metrics-server
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: metrics-server
    helm:
      releaseName: metrics-server
      values: |
        args:
          - --kubelet-insecure-tls
    repoURL: https://kubernetes-sigs.github.io/metrics-server/
    targetRevision: 3.12.2
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T16:53:52Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-05T16:34:05Z"
    deployedAt: "2025-04-05T16:34:08Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 3.12.2
    source:
      chart: metrics-server
      helm:
        releaseName: metrics-server
        values: |
          args:
            - --kubelet-insecure-tls
      repoURL: https://kubernetes-sigs.github.io/metrics-server/
      targetRevision: 3.12.2
  operationState:
    finishedAt: "2025-04-05T16:34:08Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 3.12.2
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-04-05T16:34:05Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/metrics-server created
        name: metrics-server
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/metrics-server created
        name: metrics-server
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/system:metrics-server reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get]
          APIGroups:[] Resources:[nodes/metrics] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          list watch] APIGroups:[] Resources:[pods nodes namespaces configmaps] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/system:metrics-server
          configured. Warning: resource clusterroles/system:metrics-server is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: system:metrics-server
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/system:metrics-server-aggregated-reader
          reconciled. reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          list watch] APIGroups:[metrics.k8s.io] Resources:[pods nodes] ResourceNames:[]
          NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/system:metrics-server-aggregated-reader
          configured. Warning: resource clusterroles/system:metrics-server-aggregated-reader
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: system:metrics-server-aggregated-reader
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:metrics-server Namespace:metrics-server}. clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server
          configured. Warning: resource clusterrolebindings/system:metrics-server
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: system:metrics-server
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:metrics-server Namespace:metrics-server}. clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator
          configured. Warning: resource clusterrolebindings/metrics-server:system:auth-delegator
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: metrics-server:system:auth-delegator
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: RoleBinding
        message: "rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:metrics-server Namespace:metrics-server}. rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader
          configured. Warning: resource rolebindings/metrics-server-auth-reader is
          missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: metrics-server-auth-reader
        namespace: kube-system
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/metrics-server created
        name: metrics-server
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/metrics-server created
        name: metrics-server
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiregistration.k8s.io
        hookPhase: Running
        kind: APIService
        message: apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
        name: v1beta1.metrics.k8s.io
        namespace: metrics-server
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 3.12.2
      source:
        chart: metrics-server
        helm:
          releaseName: metrics-server
          values: |
            args:
              - --kubelet-insecure-tls
        repoURL: https://kubernetes-sigs.github.io/metrics-server/
        targetRevision: 3.12.2
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: metrics-server
    namespace: metrics-server
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: metrics-server
    namespace: metrics-server
    status: Synced
    version: v1
  - group: apiregistration.k8s.io
    health:
      message: 'Passed: all checks passed'
      status: Healthy
    kind: APIService
    name: v1beta1.metrics.k8s.io
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: metrics-server
    namespace: metrics-server
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:metrics-server
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:metrics-server-aggregated-reader
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: metrics-server:system:auth-delegator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: system:metrics-server
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: RoleBinding
    name: metrics-server-auth-reader
    namespace: kube-system
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - registry.k8s.io/metrics-server/metrics-server:v0.7.2
  sync:
    comparedTo:
      destination:
        namespace: metrics-server
        server: https://kubernetes.default.svc
      source:
        chart: metrics-server
        helm:
          releaseName: metrics-server
          values: |
            args:
              - --kubelet-insecure-tls
        repoURL: https://kubernetes-sigs.github.io/metrics-server/
        targetRevision: 3.12.2
    revision: 3.12.2
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: minio-operator
spec:
  destination:
    namespace: minio-operator
    server: https://kubernetes.default.svc
  project: default
  sources:
  - chart: operator
    helm:
      releaseName: minio-operator
    repoURL: https://operator.min.io/
    targetRevision: 7.1.1
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T18:09:44Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-07T18:09:16Z"
    deployedAt: "2025-07-07T18:09:21Z"
    id: 0
    initiatedBy:
      automated: true
    revisions:
    - 7.1.1
    source:
      repoURL: ""
    sources:
    - chart: operator
      helm:
        releaseName: minio-operator
      repoURL: https://operator.min.io/
      targetRevision: 7.1.1
  operationState:
    finishedAt: "2025-07-07T18:09:21Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revisions:
        - 7.1.1
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-07-07T18:09:16Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/minio-operator created
        name: minio-operator
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: ServiceAccount
        message: serviceaccount/minio-operator created
        name: minio-operator
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/policybindings.sts.min.io
          created
        name: policybindings.sts.min.io
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Running
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/tenants.minio.min.io
          created
        name: tenants.minio.min.io
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRole
        message: "clusterrole.rbac.authorization.k8s.io/minio-operator-role reconciled.
          reconciliation required create\n\tmissing rules added:\n\t\t{Verbs:[get
          update] APIGroups:[apiextensions.k8s.io] Resources:[customresourcedefinitions]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get update list] APIGroups:[]
          Resources:[persistentvolumeclaims] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          get watch list] APIGroups:[] Resources:[namespaces nodes] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get watch create list delete deletecollection
          update patch] APIGroups:[] Resources:[pods services events configmaps] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[get watch create update list delete deletecollection]
          APIGroups:[] Resources:[secrets] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          delete get list patch update watch] APIGroups:[] Resources:[serviceaccounts]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create delete get list
          patch update watch] APIGroups:[rbac.authorization.k8s.io] Resources:[roles
          rolebindings] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get create
          list patch watch update delete] APIGroups:[apps] Resources:[statefulsets
          deployments deployments/finalizers] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get
          create list patch watch update delete] APIGroups:[batch] Resources:[jobs]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[update create get delete
          list] APIGroups:[certificates.k8s.io] Resources:[certificatesigningrequests
          certificatesigningrequests/approval certificatesigningrequests/status] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[approve sign] APIGroups:[certificates.k8s.io]
          Resources:[signers] ResourceNames:[kubernetes.io/legacy-unknown kubernetes.io/kube-apiserver-client
          kubernetes.io/kubelet-serving beta.eks.amazonaws.com/app-serving] NonResourceURLs:[]}\n\t\t{Verbs:[create]
          APIGroups:[authentication.k8s.io] Resources:[tokenreviews] ResourceNames:[]
          NonResourceURLs:[]}\n\t\t{Verbs:[*] APIGroups:[minio.min.io sts.min.io job.min.io]
          Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[*] APIGroups:[min.io]
          Resources:[*] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get update
          list] APIGroups:[monitoring.coreos.com] Resources:[prometheuses prometheusagents]
          ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[get update create] APIGroups:[coordination.k8s.io]
          Resources:[leases] ResourceNames:[] NonResourceURLs:[]}\n\t\t{Verbs:[create
          delete get list patch update deletecollection] APIGroups:[policy] Resources:[poddisruptionbudgets]
          ResourceNames:[] NonResourceURLs:[]}. clusterrole.rbac.authorization.k8s.io/minio-operator-role
          configured. Warning: resource clusterroles/minio-operator-role is missing
          the kubectl.kubernetes.io/last-applied-configuration annotation which is
          required by  apply.  apply should only be used on resources created declaratively
          by either  create --save-config or  apply. The missing annotation will be
          patched automatically."
        name: minio-operator-role
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Running
        kind: ClusterRoleBinding
        message: "clusterrolebinding.rbac.authorization.k8s.io/minio-operator-binding
          reconciled. reconciliation required create\n\tmissing subjects added:\n\t\t{Kind:ServiceAccount
          APIGroup: Name:minio-operator Namespace:minio-operator}. clusterrolebinding.rbac.authorization.k8s.io/minio-operator-binding
          configured. Warning: resource clusterrolebindings/minio-operator-binding
          is missing the kubectl.kubernetes.io/last-applied-configuration annotation
          which is required by  apply.  apply should only be used on resources created
          declaratively by either  create --save-config or  apply. The missing annotation
          will be patched automatically."
        name: minio-operator-binding
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/sts created
        name: sts
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/operator created
        name: operator
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/minio-operator created
        name: minio-operator
        namespace: minio-operator
        status: Synced
        syncPhase: Sync
        version: v1
      revision: ""
      revisions:
      - 7.1.1
      source:
        repoURL: ""
      sources:
      - chart: operator
        helm:
          releaseName: minio-operator
        repoURL: https://operator.min.io/
        targetRevision: 7.1.1
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: operator
    namespace: minio-operator
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: sts
    namespace: minio-operator
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: minio-operator
    namespace: minio-operator
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: policybindings.sts.min.io
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: tenants.minio.min.io
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: minio-operator
    namespace: minio-operator
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: minio-operator-role
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: minio-operator-binding
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceTypes:
  - Helm
  summary:
    images:
    - quay.io/minio/operator:v7.1.1
  sync:
    comparedTo:
      destination:
        namespace: minio-operator
        server: https://kubernetes.default.svc
      source:
        repoURL: ""
      sources:
      - chart: operator
        helm:
          releaseName: minio-operator
        repoURL: https://operator.min.io/
        targetRevision: 7.1.1
    revisions:
    - 7.1.1
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: minio-s3
spec:
  destination:
    namespace: minio-s3
    server: https://kubernetes.default.svc
  ignoreDifferences:
  - group: postgresql.cnpg.io
    jsonPointers:
    - /spec/managed/roles
    kind: Cluster
  project: default
  sources:
  - chart: tenant
    helm:
      releaseName: minio-s3
      valueFiles:
      - $values/helm/minio_s3_tenant_values.yaml
    repoURL: https://operator.min.io
    targetRevision: 7.1.1
  - ref: values
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-08T18:25:17Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-07-07T18:09:17Z"
    deployedAt: "2025-07-07T18:09:32Z"
    id: 0
    initiatedBy:
      automated: true
    revisions:
    - 7.1.1
    - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
    source:
      repoURL: ""
    sources:
    - chart: tenant
      helm:
        releaseName: minio-s3
        valueFiles:
        - $values/helm/minio_s3_tenant_values.yaml
      repoURL: https://operator.min.io
      targetRevision: 7.1.1
    - ref: values
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: main
  operationState:
    finishedAt: "2025-07-07T18:09:32Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revisions:
        - 7.1.1
        - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    retryCount: 1
    startedAt: "2025-07-07T18:09:17Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: Namespace
        message: namespace/minio-s3 created
        name: minio-s3
        namespace: ""
        status: Synced
        syncPhase: PreSync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Secret
        message: secret/myminio-env-configuration created
        name: myminio-env-configuration
        namespace: minio-s3
        status: Synced
        syncPhase: Sync
        version: v1
      - group: minio.min.io
        hookPhase: Running
        kind: Tenant
        message: tenant.minio.min.io/minio-s3 created
        name: minio-s3
        namespace: minio-s3
        status: Synced
        syncPhase: Sync
        version: v2
      revision: ""
      revisions:
      - 7.1.1
      - 14e8e94cfc5fefc3865348ab19b8d4186d97d549
      source:
        repoURL: ""
      sources:
      - chart: tenant
        helm:
          releaseName: minio-s3
          valueFiles:
          - $values/helm/minio_s3_tenant_values.yaml
        repoURL: https://operator.min.io
        targetRevision: 7.1.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: Secret
    name: myminio-env-configuration
    namespace: minio-s3
    status: Synced
    version: v1
  - group: minio.min.io
    health:
      message: Initialized
      status: Healthy
    kind: Tenant
    name: minio-s3
    namespace: minio-s3
    status: Synced
    version: v2
  sourceHydrator: {}
  sourceTypes:
  - Helm
  - ""
  summary:
    images:
    - quay.io/minio/minio:RELEASE.2025-04-08T15-41-24Z
    - quay.io/minio/operator-sidecar:v7.0.1
  sync:
    comparedTo:
      destination:
        namespace: minio-s3
        server: https://kubernetes.default.svc
      ignoreDifferences:
      - group: postgresql.cnpg.io
        jsonPointers:
        - /spec/managed/roles
        kind: Cluster
      source:
        repoURL: ""
      sources:
      - chart: tenant
        helm:
          releaseName: minio-s3
          valueFiles:
          - $values/helm/minio_s3_tenant_values.yaml
        repoURL: https://operator.min.io
        targetRevision: 7.1.1
      - ref: values
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
    revisions:
    - 7.1.1
    - 9757499c6f85d4922ff1f0c898f959d6fc13228b
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: nginx-proxy-manager
spec:
  destination:
    namespace: nginx-proxy-manager
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      commonLabels:
        app.kubernetes.io/instance: nginx-proxy-manager-prod
    path: kustomize/nginx-proxy-manager/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: develop
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  conditions:
  - lastTransitionTime: "2025-07-07T16:56:37Z"
    message: 'Failed to load target state: failed to generate manifest for source
      1 of 1: rpc error: code = Unknown desc = unable to resolve ''develop'' to a
      commit SHA'
    type: ComparisonError
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T16:59:28Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-05-09T04:43:06Z"
    deployedAt: "2025-05-09T04:43:06Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 90f3e97b476546a7481383ad5a01853d90a0f6ff
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        commonLabels:
          app.kubernetes.io/instance: nginx-proxy-manager-prod
      path: kustomize/nginx-proxy-manager/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  operationState:
    finishedAt: "2025-05-09T04:43:06Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 90f3e97b476546a7481383ad5a01853d90a0f6ff
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-05-09T04:43:06Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: PersistentVolume
        message: persistentvolume/npm-data serverside-applied
        name: npm-data
        namespace: nginx-proxy-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/npm-data serverside-applied
        name: npm-data
        namespace: nginx-proxy-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/nginx-proxy-manager serverside-applied
        name: nginx-proxy-manager
        namespace: nginx-proxy-manager
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/nginx-proxy-manager serverside-applied
        name: nginx-proxy-manager
        namespace: nginx-proxy-manager
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 90f3e97b476546a7481383ad5a01853d90a0f6ff
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: nginx-proxy-manager-prod
        path: kustomize/nginx-proxy-manager/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: development
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: PersistentVolume
    name: npm-data
    requiresPruning: true
    status: Unknown
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: npm-data
    namespace: nginx-proxy-manager
    requiresPruning: true
    status: Unknown
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: nginx-proxy-manager
    namespace: nginx-proxy-manager
    requiresPruning: true
    status: Unknown
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: nginx-proxy-manager
    namespace: nginx-proxy-manager
    requiresPruning: true
    status: Unknown
    version: v1
  sourceHydrator: {}
  summary:
    images:
    - jc21/nginx-proxy-manager:2.12.3
  sync:
    comparedTo:
      destination:
        namespace: nginx-proxy-manager
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
          commonLabels:
            app.kubernetes.io/instance: nginx-proxy-manager-prod
        path: kustomize/nginx-proxy-manager/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: develop
    status: Unknown
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: stirling-pdf
spec:
  destination:
    namespace: pdf
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: stirling-pdf-chart
    helm:
      releaseName: stirling-pdf
      values: |
        persistence:
          enabled: true
          accessMode: ReadWriteOnce
          size: 8Gi
          labels:
            {}
            # name: value
          path: /tmp
          pv:
            enabled: true
            pvname: "stirning-pdf-data"
            capacity:
              storage: 8Gi
            accessMode: ReadWriteOnce
            nfs:
              server: 192.168.0.15
              path: /mnt/pool1/AppData/stirlingpdf/
    repoURL: https://docs.stirlingpdf.com/Stirling-PDF-chart
    targetRevision: 1.9.1
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-05-27T16:52:23Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-05-07T20:25:56Z"
    deployedAt: "2025-05-07T20:25:59Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 1.9.1
    source:
      chart: stirling-pdf-chart
      helm:
        releaseName: stirling-pdf
        values: |
          persistence:
            enabled: true
            accessMode: ReadWriteOnce
            size: 8Gi
            labels:
              {}
              # name: value
            path: /tmp
          pv:
            enabled: true
            pvname: "stirning-pdf-data"
            capacity:
              storage: 8Gi
            accessMode: ReadWriteOnce
            nfs:
              server: 192.168.0.15
              path: /mnt/pool1/AppData/stirlingpdf/
      repoURL: https://docs.stirlingpdf.com/Stirling-PDF-chart
      targetRevision: 1.9.1
  - deployStartedAt: "2025-05-07T20:30:26Z"
    deployedAt: "2025-05-07T20:30:28Z"
    id: 1
    initiatedBy:
      automated: true
    revision: 1.9.1
    source:
      chart: stirling-pdf-chart
      helm:
        releaseName: stirling-pdf
        values: |
          persistence:
            enabled: true
            accessMode: ReadWriteOnce
            size: 8Gi
            labels:
              {}
              # name: value
            path: /tmp
            pv:
              enabled: true
              pvname: "stirning-pdf-data"
              capacity:
                storage: 8Gi
              accessMode: ReadWriteOnce
              nfs:
                server: 192.168.0.15
                path: /mnt/pool1/AppData/stirlingpdf/
      repoURL: https://docs.stirlingpdf.com/Stirling-PDF-chart
      targetRevision: 1.9.1
  operationState:
    finishedAt: "2025-05-07T20:34:52Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        autoHealAttemptsCount: 2
        prune: true
        resources:
        - group: apps
          kind: Deployment
          name: stirling-pdf-stirling-pdf-chart
        revision: 1.9.1
        syncOptions:
        - CreateNamespace=true
    phase: Succeeded
    startedAt: "2025-05-07T20:34:47Z"
    syncResult:
      resources:
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/stirling-pdf-stirling-pdf-chart created
        name: stirling-pdf-stirling-pdf-chart
        namespace: pdf
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 1.9.1
      source:
        chart: stirling-pdf-chart
        helm:
          releaseName: stirling-pdf
          values: |
            persistence:
              enabled: true
              accessMode: ReadWriteOnce
              size: 8Gi
              labels:
                {}
                # name: value
              path: /tmp
              pv:
                enabled: true
                pvname: "stirning-pdf-data"
                capacity:
                  storage: 8Gi
                accessMode: ReadWriteOnce
                nfs:
                  server: 192.168.0.15
                  path: /mnt/pool1/AppData/stirlingpdf/
        repoURL: https://docs.stirlingpdf.com/Stirling-PDF-chart
        targetRevision: 1.9.1
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: PersistentVolume
    name: stirning-pdf-data
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: stirling-pdf-stirling-pdf-chart
    namespace: pdf
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: stirling-pdf-stirling-pdf-chart
    namespace: pdf
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: stirling-pdf-stirling-pdf-chart
    namespace: pdf
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: stirling-pdf-stirling-pdf-chart
    namespace: pdf
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - docker.stirlingpdf.com/stirlingtools/stirling-pdf:0.45.6
  sync:
    comparedTo:
      destination:
        namespace: pdf
        server: https://kubernetes.default.svc
      source:
        chart: stirling-pdf-chart
        helm:
          releaseName: stirling-pdf
          values: |
            persistence:
              enabled: true
              accessMode: ReadWriteOnce
              size: 8Gi
              labels:
                {}
                # name: value
              path: /tmp
              pv:
                enabled: true
                pvname: "stirning-pdf-data"
                capacity:
                  storage: 8Gi
                accessMode: ReadWriteOnce
                nfs:
                  server: 192.168.0.15
                  path: /mnt/pool1/AppData/stirlingpdf/
        repoURL: https://docs.stirlingpdf.com/Stirling-PDF-chart
        targetRevision: 1.9.1
    revision: 1.9.1
    status: Synced
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  finalizers:
  - resources-finalizer.argocd.argoproj.io
  name: vaultwarden
spec:
  destination:
    namespace: zero-trust
    server: https://kubernetes.default.svc
  project: default
  source:
    kustomize:
      commonAnnotations:
        argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    path: kustomize/vaultwarden/overlays/prod
    repoURL: https://github.com/codesenju/kubelab.git
    targetRevision: main
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-07-07T17:03:34Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-04-26T22:59:29Z"
    deployedAt: "2025-04-26T22:59:29Z"
    id: 0
    initiatedBy:
      automated: true
    revision: 8700df70f89d7510906cb26a868770668d343ad8
    source:
      kustomize:
        commonAnnotations:
          argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
      path: kustomize/vaultwarden/overlays/prod
      repoURL: https://github.com/codesenju/kubelab.git
      targetRevision: development
  operationState:
    finishedAt: "2025-04-26T22:59:29Z"
    message: successfully synced (all tasks run)
    operation:
      initiatedBy:
        automated: true
      retry:
        limit: 5
      sync:
        prune: true
        revision: 8700df70f89d7510906cb26a868770668d343ad8
        syncOptions:
        - CreateNamespace=true
        - ServerSideApply=true
        - RespectIgnoreDifferences=true
    phase: Succeeded
    startedAt: "2025-04-26T22:59:29Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Running
        kind: PersistentVolume
        message: persistentvolume/vw-data serverside-applied
        name: vw-data
        namespace: zero-trust
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: PersistentVolumeClaim
        message: persistentvolumeclaim/vw-data serverside-applied
        name: vw-data
        namespace: zero-trust
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Running
        kind: Service
        message: service/vaultwarden serverside-applied
        name: vaultwarden
        namespace: zero-trust
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Running
        kind: Deployment
        message: deployment.apps/vaultwarden serverside-applied
        name: vaultwarden
        namespace: zero-trust
        status: Synced
        syncPhase: Sync
        version: v1
      revision: 8700df70f89d7510906cb26a868770668d343ad8
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        path: kustomize/vaultwarden/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: development
  reconciledAt: "2025-07-08T20:01:44Z"
  resources:
  - kind: PersistentVolume
    name: vw-data
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: PersistentVolumeClaim
    name: vw-data
    namespace: zero-trust
    status: Synced
    version: v1
  - health:
      status: Healthy
    kind: Service
    name: vaultwarden
    namespace: zero-trust
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: vaultwarden
    namespace: zero-trust
    status: Synced
    version: v1
  sourceHydrator: {}
  sourceType: Kustomize
  summary:
    images:
    - vaultwarden/server:latest
  sync:
    comparedTo:
      destination:
        namespace: zero-trust
        server: https://kubernetes.default.svc
      source:
        kustomize:
          commonAnnotations:
            argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
        path: kustomize/vaultwarden/overlays/prod
        repoURL: https://github.com/codesenju/kubelab.git
        targetRevision: main
    revision: 9757499c6f85d4922ff1f0c898f959d6fc13228b
    status: Synced
---
